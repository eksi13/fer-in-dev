{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee41e651-be67-4da3-8fbe-857210e2e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import concurrent.futures\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a016d1e8-f90c-42f1-a05b-9e648af36ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimh_path = './NIMH-CHEFS'\n",
    "out_path = './out'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b05a0fe-2f07-4517-b504-f1fd580bbcb8",
   "metadata": {},
   "source": [
    "### Folder Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69dd04a7-4112-451b-bc83-940fa17b9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a list of subfolders\n",
    "def get_subfolders(path):\n",
    "    return [os.path.join(path, folder)\n",
    "            for folder in os.listdir(path) \n",
    "            if folder != '.ipynb_checkpoints' \n",
    "            and folder != '.DS_Store']\n",
    "\n",
    "# gets inly the names of folders of a folder list\n",
    "def get_folder_names(folder_list):\n",
    "    return [os.path.basename(folder) for folder in folder_list]\n",
    "\n",
    "# gets all the image files of a given folder\n",
    "def get_image_files_from_folder(folder):\n",
    "    return [os.path.join(folder, file_name)\n",
    "            for file_name in os.listdir(folder) \n",
    "            if file_name.endswith('.jpg')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a1e27",
   "metadata": {},
   "source": [
    "### Image Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa976982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves an image to a given path, creates path, if it doesn't exist, names it after the changes done, e.g. 'resized', 'cropped'\n",
    "def save_image(image, folder_path_out, image_name, changes):\n",
    "    image_name = os.path.splitext(image_name)[0]\n",
    "    if not os.path.exists(folder_path_out):\n",
    "        os.makedirs(folder_path_out)\n",
    "    cv2.imwrite(f'{folder_path_out}/{image_name}_{changes}.jpg', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c1fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = get_subfolders(nimh_path)\n",
    "folder_names = get_folder_names(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff11e4",
   "metadata": {},
   "source": [
    "### Grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c02c440",
   "metadata": {},
   "source": [
    "#### Grayscale utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8918b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grayscale(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c2a188-8381-43c5-ba26-2f24d2fe7666",
   "metadata": {},
   "source": [
    "### Crop faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d948e3",
   "metadata": {},
   "source": [
    "#### Face detection utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05523ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection using haar cascades // viola jones\n",
    "# read images, crop and create new dir to store the crops\n",
    "\n",
    "def find_face(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    face = face_classifier.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40))\n",
    "    return face\n",
    "\n",
    "# returns cropped image in cv2 format\n",
    "def crop_face(face, img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    x, y, w, h = face\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 4)\n",
    "    return img[y:y + h, x:x + w]\n",
    "\n",
    "def process_face_and_save(face_coords, image_path, file_name, folder):\n",
    "    try:\n",
    "        crop_and_save(face_coords, image_path, file_name, folder)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {file_name}: {e}\")\n",
    "\n",
    "def process_folder_crop(folder_list):\n",
    "    for folder in folder_list:\n",
    "        display(folder_path_out)\n",
    "        image_files_in_folder = get_image_files_from_folder(folder)\n",
    "        for image_path in tqdm(image_files):\n",
    "            face = find_face(image_path)\n",
    "            for face_coords in face:\n",
    "                img = crop_face(face, image_path)\n",
    "                save_image(img, folder_path_out, os.path.basename(image_path), 'cropped')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b44ee3",
   "metadata": {},
   "source": [
    "#### Detect face and crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cdbc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "folders = [os.path.join(nimh_path, folder) for folder in os.listdir(nimh_path) if folder != '.ipynb_checkpoints' and folder != '.DS_Store']\n",
    "# display(folders)\n",
    "\n",
    "# multithreading\n",
    "# with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "#    executor.map(process_folder, folders)\n",
    "\n",
    "# single-threading\n",
    "for folder in folders:\n",
    "    process_folder_crop(folder)\n",
    "\n",
    "t2 = time.time()\n",
    "display(t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38325ff0",
   "metadata": {},
   "source": [
    "### Resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730dd0c9",
   "metadata": {},
   "source": [
    "#### Set parameters for resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2466c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (256, 256)\n",
    "downsampling = cv2.INTER_AREA\n",
    "upsampling = cv2.INTER_CUBIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f351e70e",
   "metadata": {},
   "source": [
    "#### Resizing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5a20fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizes images based on given size and interpolation method\n",
    "def resize_image(image_file, size, interpolation):\n",
    "    img = cv2.imread(image_file)\n",
    "    return cv2.resize(img, dsize=size, interpolation=interpolation)\n",
    "\n",
    "# does all the magic\n",
    "def process_images_resize(folder_list, size, interpolation):\n",
    "    for folder in folder_list:\n",
    "        display(folder)\n",
    "        image_files_in_folder = get_image_files_from_folder(folder)\n",
    "        for image_file in tqdm(image_files_in_folder):\n",
    "            res_img = resize_image(image_file, size, interpolation)\n",
    "            folder_path_out = f'out/resized/{os.path.basename(folder)}'\n",
    "            img_name = os.path.basename(image_file)\n",
    "            save_image(res_img, folder_path_out, img_name, 'resized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e0b8a",
   "metadata": {},
   "source": [
    "#### Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee713f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_images_resize(folders, size, upsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be9781-f50b-4921-9ae5-301f37f52266",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./img.jpg\")\n",
    "\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e71f02-c2ab-495a-8afd-0a83ecfca73b",
   "metadata": {},
   "source": [
    "#### Mediapipe Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b32aa06-3d56-4bae-ad14-936c2bb542a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "  face_landmarks_list = detection_result.face_landmarks\n",
    "  annotated_image = np.copy(rgb_image)\n",
    "\n",
    "  # Loop through the detected faces to visualize.\n",
    "  for idx in range(len(face_landmarks_list)):\n",
    "    face_landmarks = face_landmarks_list[idx]\n",
    "\n",
    "    # Draw the face landmarks.\n",
    "    face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "    face_landmarks_proto.landmark.extend([\n",
    "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks\n",
    "    ])\n",
    "\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "        image=annotated_image,\n",
    "        landmark_list=face_landmarks_proto,\n",
    "        connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp.solutions.drawing_styles\n",
    "        .get_default_face_mesh_tesselation_style())\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "        image=annotated_image,\n",
    "        landmark_list=face_landmarks_proto,\n",
    "        connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp.solutions.drawing_styles\n",
    "        .get_default_face_mesh_contours_style())\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "        image=annotated_image,\n",
    "        landmark_list=face_landmarks_proto,\n",
    "        connections=mp.solutions.face_mesh.FACEMESH_IRISES,\n",
    "          landmark_drawing_spec=None,\n",
    "          connection_drawing_spec=mp.solutions.drawing_styles\n",
    "          .get_default_face_mesh_iris_connections_style())\n",
    "\n",
    "  return annotated_image\n",
    "\n",
    "def plot_face_blendshapes_bar_graph(face_blendshapes):\n",
    "  # Extract the face blendshapes category names and scores.\n",
    "  face_blendshapes_names = [face_blendshapes_category.category_name for face_blendshapes_category in face_blendshapes]\n",
    "  face_blendshapes_scores = [face_blendshapes_category.score for face_blendshapes_category in face_blendshapes]\n",
    "  # The blendshapes are ordered in decreasing score value.\n",
    "  face_blendshapes_ranks = range(len(face_blendshapes_names))\n",
    "\n",
    "  fig, ax = plt.subplots(figsize=(12, 12))\n",
    "  bar = ax.barh(face_blendshapes_ranks, face_blendshapes_scores, label=[str(x) for x in face_blendshapes_ranks])\n",
    "  ax.set_yticks(face_blendshapes_ranks, face_blendshapes_names)\n",
    "  ax.invert_yaxis()\n",
    "\n",
    "  # Label each bar with values\n",
    "  for score, patch in zip(face_blendshapes_scores, bar.patches):\n",
    "    plt.text(patch.get_x() + patch.get_width(), patch.get_y(), f\"{score:.4f}\", va=\"top\")\n",
    "\n",
    "  ax.set_xlabel('Score')\n",
    "  ax.set_title(\"Face Blendshapes\")\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da58de44-01a4-4a48-9bd0-44d9248f444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04448605-4ab3-4719-b26d-98057d01316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an FaceLandmarker object\n",
    "base_options = python.BaseOptions(model_asset_path='./face_landmarker.task')\n",
    "options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
    "                                       output_face_blendshapes=True,\n",
    "                                       output_facial_transformation_matrixes=True,\n",
    "                                       num_faces=1)\n",
    "detector = vision.FaceLandmarker.create_from_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdb3e706-cefa-48ca-86c8-dc3b0b06a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mp.Image.create_from_file(\"./img.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "833c5cd7-2815-4a68-95e4-28fbfada3a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect face landmarks from the input image\n",
    "detection_result = detector.detect(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71fad72-5f8c-49ad-a808-de0133812212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the detection result, visualize it\n",
    "annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)\n",
    "res_img = cv2.cvtColor(annotated_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "plt.imshow(res_img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
