{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try: \n",
    "    import cv2\n",
    "    import torch\n",
    "    import torchvision\n",
    "    import sklearn.svm\n",
    "except:\n",
    "    %pip install opencv-python-headless==4.9.0.80\n",
    "    %pip install torch\n",
    "    %pip install torchvision\n",
    "    %pip install torchsummary \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import cuda\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import pickle \n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "from torchsummary import summary\n",
    "from PIL import Image\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "print('import successful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Parameters\n",
    "BASE_PATH = Path('/home/jovyan/work/data/out')\n",
    "\n",
    "EMOREACT = 'EmoReact'\n",
    "FER = 'FER-2013'\n",
    "KDEF = 'KDEF-AKDEF'\n",
    "NIMH = 'NIMH-CHEFS'\n",
    "INTERNAL = Path('/home/jovyan/work/output/extracted_faces')\n",
    "CROSS = Path('/home/jovyan/work/cross-label/extracted_faces')\n",
    "\n",
    "DATASET = 'Internal Cross Label'\n",
    "\n",
    "DATA_PATH = Path('/home/jovyan/work/data/out/') / DATASET\n",
    "DATA_PATH = CROSS\n",
    "\n",
    "# Dataset-specific paths\n",
    "LABELS = [f.name for f in DATA_PATH.iterdir() if f.is_dir()]\n",
    "IMAGE_PATHS = list(DATA_PATH.rglob('*.jpg'))\n",
    "print(len(IMAGE_PATHS))\n",
    "\n",
    "# Constants for splitting dataset\n",
    "TRAIN = 'train'\n",
    "TEST = 'test'\n",
    "VAL = 'val'\n",
    "\n",
    "# Model parameters\n",
    "MODEL_PATH = Path('/home/jovyan/work/models')\n",
    "BATCH_SIZE = 16\n",
    "SUBSET_RATIO = 0.1\n",
    "SUBSET = False\n",
    "\n",
    "# Constants for feature extraction\n",
    "FEATURES = 'feature-extraction'\n",
    "TRANSFER = 'transfer-learning'\n",
    "FINETUNE = 'fine-tuning'\n",
    "\n",
    "# Cuda parameters\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.get_device_name(0)\n",
    "\n",
    "# feature extaraction\n",
    "orientations = 7\n",
    "pixels_per_cell = 8\n",
    "cells_per_block = 4\n",
    "\n",
    "hog_params = { \n",
    "    'orientations': orientations,\n",
    "    'pixels_per_cell': pixels_per_cell,\n",
    "    'cells_per_block': cells_per_block\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('/home/jovyan/work/output/extracted_faces-improved/subset')\n",
    "#LABELS = [f.name for f in (PATH / TRAIN).iterdir() if f.is_dir()]\n",
    "\n",
    "DATASET = 'internal-improved'\n",
    "#LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data_path, transforms=None, phase='train'):\n",
    "        self.data_path = Path(data_path) / phase\n",
    "        self.transform = transforms[phase]\n",
    "        self.phase = phase\n",
    "\n",
    "        self.classes = self._get_classes()\n",
    "        self.image_paths = self._get_image_paths()\n",
    "        self.num_classes = len(self.classes)\n",
    "\n",
    "        self.class_to_int = {class_name: idx for idx, class_name in enumerate(self.classes)}\n",
    "        self.int_to_class = {idx: class_name for class_name, idx in self.class_to_int.items()}\n",
    "\n",
    "    def _get_classes(self):\n",
    "        return [f.name for f in self.data_path.iterdir() if f.is_dir()]\n",
    "\n",
    "    def _get_image_paths(self):\n",
    "        paths = list(self.data_path.rglob('*.jpg'))\n",
    "        random.shuffle(paths)\n",
    "        return paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx])\n",
    "        img_path = self.image_paths[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = Path(img_path).parent.name\n",
    "        label = self.class_to_int[label]  # Convert label to integer\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def show_distribution(self):\n",
    "        labels_count = Counter([self.__getitem__(i)[1] for i in range(len(self.image_paths))])\n",
    "        sorted_counts = sorted(labels_count.items())\n",
    "        labels, counts = zip(*sorted_counts)\n",
    "\n",
    "        plt.figure(figsize=(10, 3))\n",
    "        bars = plt.bar(labels, counts, color='skyblue')\n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Counts per Class')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        for bar, count in zip(bars, counts):\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5, count,\n",
    "                    ha='center', va='bottom', color='black', fontsize=8)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def idx_to_class(self, idx_list):\n",
    "        return [self.int_to_class[idx] for idx in idx_list]\n",
    "\n",
    "    def class_to_idx(self, class_list):\n",
    "        return [self.class_to_int[class_name] for class_name in class_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Transforms & Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    TRAIN: transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    VAL: transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    TEST: transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = { x: Dataset(DATA_PATH, transforms=data_transforms, phase=x) for x in [TRAIN, VAL, TEST] }\n",
    "dataloaders = { x: torch.utils.data.DataLoader(datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4) for x in [TRAIN, VAL, TEST] }\n",
    "dataset_sizes = { x : len(datasets[x]) for x in [TRAIN, VAL, TEST] }\n",
    "NUM_CLASSES = datasets[TRAIN].num_classes\n",
    "print(datasets[TRAIN].classes)\n",
    "print(datasets[TRAIN].data_path)\n",
    "print(datasets[TEST].data_path)\n",
    "print(datasets[VAL].data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[VAL].show_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[TEST].show_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[TRAIN].show_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score\n",
    "\n",
    "def train_model(vgg, criterion, optimizer, scheduler, num_epochs=10, patience=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_acc = 0.0\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    avg_loss_val = 0\n",
    "    avg_acc_val = 0\n",
    "\n",
    "    train_batches = len(dataloaders[TRAIN])\n",
    "    val_batches = len(dataloaders[VAL])\n",
    "\n",
    "    best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # Lists to store metrics for plotting\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "        print('-' * 10)\n",
    "\n",
    "        loss_train = 0\n",
    "        loss_val = 0\n",
    "        acc_train = 0\n",
    "        acc_val = 0\n",
    "        \n",
    "        vgg.train(True)\n",
    "\n",
    "        # Iterate through batches of training set\n",
    "        for i, data in enumerate(dataloaders[TRAIN]):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"\\rTraining batch {i}/{train_batches}\", flush=True)\n",
    "            \n",
    "            # Set input and labels to the batch features and labels\n",
    "            inputs = data[0]\n",
    "            labels = data[1]\n",
    "\n",
    "            # Move to cuda if possible\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            # Do the learning stuff & update loss etc.\n",
    "            optimizer.zero_grad()\n",
    "            outputs = vgg(inputs)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            # Backward & optimize\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()                \n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            acc_train += torch.sum(preds == labels.data)\n",
    "            \n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        print()\n",
    "        avg_loss = loss_train / dataset_sizes[TRAIN]\n",
    "        avg_acc = acc_train / dataset_sizes[TRAIN]\n",
    "\n",
    "        # Set to evaluation mode\n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        # Iterate through batches of validation set\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(dataloaders[VAL]):\n",
    "                if i % 100 == 0:\n",
    "                    print(f\"\\rValidation batch {i}/{val_batches}\", flush=True)\n",
    "                \n",
    "                # Set input and labels to the batch features and labels\n",
    "                inputs = data[0]\n",
    "                labels = data[1]\n",
    "    \n",
    "                # Move to cuda if possible\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "    \n",
    "                # Do the learning stuff & update loss etc.\n",
    "                outputs = vgg(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss_val += loss.item()\n",
    "                acc_val += torch.sum(preds == labels.data)\n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                del inputs, labels, outputs, preds\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_loss_val = loss_val / dataset_sizes[VAL]\n",
    "        avg_acc_val = balanced_accuracy_score(all_labels, all_preds)\n",
    "\n",
    "        # Store metrics for plotting\n",
    "        train_losses.append(avg_loss)\n",
    "        val_losses.append(avg_loss_val)\n",
    "        train_accuracies.append(avg_acc.item())\n",
    "        val_accuracies.append(avg_acc_val)\n",
    "\n",
    "        print()\n",
    "        print(f\"Epoch {epoch} result: \")\n",
    "        print(f\"Avg loss (train): {avg_loss:.4f}\")\n",
    "        print(f\"Avg acc (train): {avg_acc:.4f}\")\n",
    "        print(f\"Avg loss (val): {avg_loss_val:.4f}\")\n",
    "        print(f\"Avg acc (val): {avg_acc_val:.4f}\")\n",
    "        print('-' * 10)\n",
    "        print()\n",
    "\n",
    "        # Update best acc save best model weights\n",
    "        if avg_acc_val > best_acc:\n",
    "            best_acc = avg_acc_val\n",
    "            best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        # Early stopping\n",
    "        if epochs_no_improve == patience:\n",
    "            print(f'Early stopping triggered after {patience} epochs without improvement')\n",
    "            break\n",
    "\n",
    "    # Compute training time\n",
    "    elapsed_time = time.time() - since\n",
    "\n",
    "    # Print all the results\n",
    "    print()\n",
    "    print(f\"Training completed in {elapsed_time // 60:.0f}m {elapsed_time % 60:.0f}s\")\n",
    "    print(f\"Best acc: {best_acc:.4f}\")\n",
    "    print()\n",
    "\n",
    "    vgg.load_state_dict(best_model_wts)\n",
    "\n",
    "    # Compute evaluation metrics on the best model\n",
    "    vgg.train(False)\n",
    "    vgg.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloaders[VAL]):\n",
    "            # Set input and labels to the batch features and labels\n",
    "            inputs = data[0]\n",
    "            labels = data[1]\n",
    "\n",
    "            # Move to cuda if possible\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            # Do the learning stuff & update loss etc.\n",
    "            outputs = vgg(inputs)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds, target_names=LABELS)\n",
    "    acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    print(f\"Weighted Accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Plotting the results\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return vgg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Init the VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the VGG model\n",
    "vgg16 = models.vgg16(weights='IMAGENET1K_V1')\n",
    "vgg16 = vgg16.to(DEVICE)\n",
    "\n",
    "# Freeze feature layers\n",
    "for param in vgg16.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Make classifier trainable\n",
    "for param in vgg16.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "vgg16.classifier[-1] = torch.nn.Linear(in_features=vgg16.classifier[-1].in_features, out_features=NUM_CLASSES)\n",
    "\n",
    "vgg16 = vgg16.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(vgg16.parameters(), lr=0.0001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "\n",
    "trained_vgg16 = train_model(vgg16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=50)\n",
    "\n",
    "elapsed_time = time.time() - since\n",
    "print(f\"Training completed in {elapsed_time // 60:.0f}m {elapsed_time % 60:.0f}s\")\n",
    "\n",
    "pkl_name = f'{DATASET}_VGG16.pkl'\n",
    "pkl_path = str(MODEL_PATH / 'PICKLE' / pkl_name)\n",
    "\n",
    "with open(pkl_path, 'wb') as f:\n",
    "    pickle.dump(trained_vgg16, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
