{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "#from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path('/project/volume/data/in/EmoReact')\n",
    "LABELS_PATH = Path('/project/volume/data/in/EmoReact/EmoReact_V_1.0/Labels/')\n",
    "ORIG_FOLDERS = ['Test', 'Train', 'Validation']\n",
    "LABEL_FILES = ['test_labels.text', 'train_labels.text/', 'val_labels.text']\n",
    "\n",
    "labels = ['Curiosity', 'Uncertainty', 'Excitement', 'Happiness', 'Surprise', 'Disgust', 'Fear', 'Frustration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders():\n",
    "    for label in labels:\n",
    "        label_path = BASE_PATH / Path(label)\n",
    "        if not label_path.exists():\n",
    "            label_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def read_labels():\n",
    "    df_train, df_test, df_val = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "    for label in LABEL_FILES:\n",
    "        path = LABELS_PATH / Path(label)\n",
    "        df = pd.read_csv(str(path), header=None)\n",
    "        df = df.drop(columns=[df.columns[-1]])\n",
    "        df.columns = labels\n",
    "        if 'test_labels.text' in label:\n",
    "            df_train = pd.concat([df_train, df], ignore_index=True)\n",
    "        elif 'train_labels.text' in label:\n",
    "            df_test = pd.concat([df_test, df], ignore_index=True)\n",
    "        elif 'val_labels.text' in label:\n",
    "            df_val = pd.concat([df_val, df], ignore_index=True)\n",
    "\n",
    "    return df_train, df_test, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, df_val = read_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files():\n",
    "    for folder in tqdm(ORIG_FOLDERS):\n",
    "        folder_path = BASE_PATH / Path('EmoReact_V_1.0/Data') / folder\n",
    "        if 'Test' in folder:\n",
    "            df = df_test\n",
    "        elif 'Train' in folder:\n",
    "            df = df_train\n",
    "        elif 'Validation' in folder:\n",
    "            df = df_val\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for file_idx, file in enumerate(list(folder_path.rglob('*.mp4'))):\n",
    "            if file_idx >= len(df):\n",
    "                break\n",
    "            file_label = df.loc[file_idx].idxmax() \n",
    "            destination_folder = BASE_PATH / Path(file_label)\n",
    "            destination_folder.mkdir(exist_ok=True, parents=True)\n",
    "            shutil.move(str(file), str(destination_folder))\n",
    "        \n",
    "        if folder_path.exists() and folder_path.is_dir():\n",
    "            shutil.rmtree(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_lenght():\n",
    "    video_lengths = []\n",
    "    for file in list(BASE_PATH.rglob('*.mp4')):\n",
    "        cap = cv2.VideoCapture(str(file))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = frame_count / fps\n",
    "        video_lengths.append(duration)\n",
    "        cap.release()\n",
    "    return video_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_lengths = get_video_lenght()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_length = np.mean(video_lengths)\n",
    "std_dev = np.std(video_lengths)\n",
    "\n",
    "print(average_length, std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames():\n",
    "    for p in tqdm(list(BASE_PATH.rglob('*.mp4'))):\n",
    "        cap = cv2.VideoCapture(str(p))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        nbr_frames = int(total_frames * 0.25)\n",
    "        #nbr_frames = 110\n",
    "\n",
    "        for frame_idx in range(nbr_frames):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            _, frame = cap.read()\n",
    "            frame_file_name = Path(str(p.stem) + f'_{frame_idx}.jpg')\n",
    "            frame_path = str(p.parent / frame_file_name)\n",
    "            #print(frame_path)\n",
    "            if not os.path.exists(str(frame_path)):\n",
    "                cv2.imwrite(frame_path, frame)\n",
    "    \n",
    "        cap.release()\n",
    "        if os.path.exists(str(p)):\n",
    "            os.remove(str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe import Image\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_detect = '/project/volume/models/blaze_face_short_range.tflite'\n",
    "model_path_mesh = '/project/volume/models/face_landmarker.task'\n",
    "\n",
    "base_options_detect = python.BaseOptions(model_asset_path=model_path_detect)\n",
    "options_detect = vision.FaceDetectorOptions(base_options=base_options_detect)\n",
    "detector_detect = vision.FaceDetector.create_from_options(options_detect)\n",
    "\n",
    "base_options_mesh = python.BaseOptions(model_asset_path=model_path_mesh)\n",
    "options_mesh = vision.FaceLandmarkerOptions(base_options=base_options_mesh,\n",
    "                                       output_face_blendshapes=False,\n",
    "                                       output_facial_transformation_matrixes=True,\n",
    "                                       num_faces=1)\n",
    "detector_mesh = vision.FaceLandmarker.create_from_options(options_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mp_cv2_image(image_path):\n",
    "    return Image.create_from_file(str(image_path)), cv2.imread(str(image_path))\n",
    "\n",
    "def colortogray(img):\n",
    "    imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return imgray\n",
    "\n",
    "def resizeImage(image, size):\n",
    "    return cv2.resize(image, (size,size))\n",
    "\n",
    "def extract_faces(img_cv2, detection_results):\n",
    "    faces = []\n",
    "    for d in detection_results.detections:  \n",
    "        bbox = d.bounding_box\n",
    "        origin_x, origin_y, width, height = bbox.origin_x, bbox.origin_y, bbox.width, bbox.height\n",
    "        cropped_img = img_cv2[origin_y:origin_y+height, origin_x:origin_x+width]\n",
    "        faces.append(cropped_img)\n",
    "    return faces        \n",
    "\n",
    "def detect_faces():\n",
    "    for file in tqdm(list(BASE_PATH.rglob('*.jpg'))):\n",
    "        img_mp, img_cv2 = read_mp_cv2_image(str(file))\n",
    "        img_cv2 = colortogray(img_cv2)\n",
    "        resizeImage(img_cv2, 64)\n",
    "        detection_results = detector_detect.detect(img_mp)\n",
    "        faces = extract_faces(img_cv2, detection_results)\n",
    "        for face_idx, face in enumerate(faces):\n",
    "            face_file_name = Path(str(file.stem) + f'_face_{face_idx}.jpg')\n",
    "            face_path = str(file.parent / face_file_name)\n",
    "\n",
    "            if not os.path.exists(str(face_path)):\n",
    "                    cv2.imwrite(face_path, face)\n",
    "\n",
    "        if os.path.exists(str(file)):\n",
    "            os.remove(str(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prop = 0.6\n",
    "test_prop = 0.2\n",
    "valid_prop = 0.2\n",
    "\n",
    "number_of_images = len(list(BASE_PATH.rglob('*.jpg')))\n",
    "\n",
    "print(\"[INFO] Number of images in total ...\" + str(number_of_images))\n",
    "\n",
    "n_train = int((number_of_images * train_prop) + 0.5)\n",
    "n_valid = int((number_of_images * valid_prop) + 0.5)\n",
    "n_test = number_of_images - n_train - n_valid\n",
    "\n",
    "\n",
    "print(f\"[INFO] Number of images used in training ... {str(n_train)} ({str(train_prop * 100)}%)\")\n",
    "print(f\"[INFO] Number of images used in testing ... {str(n_test)} ({str(test_prop * 100)}%)\")\n",
    "print(f\"[INFO] Number of images used in validation ...{str(n_valid)} ({str(valid_prop * 100)}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_move():\n",
    "    for label in tqdm(labels):\n",
    "        folder_path = BASE_PATH / label\n",
    "        print(folder_path)\n",
    "        #print(len(list(folder_path.rglob('*.jpg'))))\n",
    "        train_destination = BASE_PATH / \"train\" / label\n",
    "        val_destination = BASE_PATH / \"val\" / label\n",
    "        test_destination = BASE_PATH / \"test\" / label\n",
    "\n",
    "        train_destination.mkdir(parents=True, exist_ok=True)\n",
    "        val_destination.mkdir(parents=True, exist_ok=True)\n",
    "        test_destination.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        files = list(folder_path.rglob('*.jpg'))\n",
    "        random.shuffle(files)\n",
    "        train_n = (int((len(files) * train_prop) + 0.5))\n",
    "        val_n = (int((len(files) * valid_prop) + 0.2))\n",
    "        \n",
    "        for file_idx, file in enumerate(list(folder_path.rglob('*.jpg'))):\n",
    "            if file_idx < train_n:\n",
    "                shutil.move(str(file), train_destination)\n",
    "            elif file_idx < train_n + val_n:\n",
    "                shutil.move(str(file), val_destination)\n",
    "            else:\n",
    "                shutil.move(str(file), test_destination)\n",
    "\n",
    "        if folder_path.exists() and folder_path.is_dir():\n",
    "            shutil.rmtree(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_and_move()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(BASE_PATH.rglob('*.jpg'))))\n",
    "\n",
    "print(14952 * 0.6)\n",
    "print(14952 * 0.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
