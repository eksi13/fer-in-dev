{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path('/project/volume/data/in/EmoReact')\n",
    "LABELS_PATH = Path('/project/volume/data/in/EmoReact/EmoReact_V_1.0/Labels/')\n",
    "ORIG_FOLDERS = ['Test', 'Train', 'Validation']\n",
    "LABEL_FILES = ['test_labels.text', 'train_labels.text/', 'val_labels.text']\n",
    "\n",
    "labels = ['Curiosity', 'Uncertainty', 'Excitement', 'Happiness', 'Surprise', 'Disgust', 'Fear', 'Frustration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders():\n",
    "    for label in labels:\n",
    "        label_path = BASE_PATH / Path(label)\n",
    "        if not label_path.exists():\n",
    "            label_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def read_labels():\n",
    "    df_train, df_test, df_val = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "    for label in LABEL_FILES:\n",
    "        path = LABELS_PATH / Path(label)\n",
    "        df = pd.read_csv(str(path), header=None)\n",
    "        df = df.drop(columns=[df.columns[-1]])\n",
    "        df.columns = labels\n",
    "        if 'test_labels.text' in label:\n",
    "            df_train = pd.concat([df_train, df], ignore_index=True)\n",
    "        elif 'train_labels.text' in label:\n",
    "            df_test = pd.concat([df_test, df], ignore_index=True)\n",
    "        elif 'val_labels.text' in label:\n",
    "            df_val = pd.concat([df_val, df], ignore_index=True)\n",
    "\n",
    "    return df_train, df_test, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folders(labels, BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, df_val = read_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files():\n",
    "    for folder in tqdm(ORIG_FOLDERS):\n",
    "        folder_path = BASE_PATH / Path('EmoReact_V_1.0/Data') / folder\n",
    "        if 'Test' in folder:\n",
    "            df = df_test\n",
    "        elif 'Train' in folder:\n",
    "            df = df_train\n",
    "        elif 'Validation' in folder:\n",
    "            df = df_val\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for file_idx, file in enumerate(list(folder_path.rglob('*.mp4'))):\n",
    "            file_label = df.loc[file_idx].idxmax() \n",
    "            destination_folder = BASE_PATH / Path(file_label)\n",
    "            destination_folder.mkdir(exist_ok=True, parents=True)\n",
    "            shutil.move(str(file), str(destination_folder))\n",
    "        \n",
    "        if folder_path.exists() and folder_path.is_dir():\n",
    "            shutil.rmtree(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1026.25it/s]\n"
     ]
    }
   ],
   "source": [
    "move_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moce the image files\n",
    "for folder_idx, folder in enumerate(orig_folders):\n",
    "    files = os.listdir(BASE_DIR + folder)\n",
    "    number_of_images = len([name for name in files])\n",
    "    n_train = int((number_of_images * 0.6) + 0.5)\n",
    "    n_valid = int((number_of_images*0.25) + 0.5)\n",
    "    n_test = number_of_images - n_train - n_valid\n",
    "    print(number_of_images, n_train, n_valid, n_test)\n",
    "    for idx, file in enumerate(files):\n",
    "        file_name = BASE_DIR + folder + file\n",
    "        if idx < n_train:\n",
    "            shutil.move(file_name, BASE_DIR + \"train/\" + names[folder_idx])\n",
    "        elif idx < n_train + n_valid:\n",
    "            shutil.move(file_name, BASE_DIR + \"val/\" + names[folder_idx])\n",
    "        else:\n",
    "            shutil.move(file_name, BASE_DIR + \"test/\" + names[folder_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1102"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_videos = len(list(BASE_PATH.rglob('*.mp4')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_lengths = []\n",
    "for file in list(BASE_PATH.rglob('*.mp4')):\n",
    "    cap = cv2.VideoCapture(str(file))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = frame_count / fps\n",
    "    video_lengths.append(duration)\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.860247103750756 2.064505095633643\n"
     ]
    }
   ],
   "source": [
    "average_length = np.mean(video_lengths)\n",
    "std_dev = np.std(video_lengths)\n",
    "\n",
    "print(average_length, std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames():\n",
    "    for p in list(BASE_PATH.rglob('*.mp4')):\n",
    "        print(p)\n",
    "        cap = cv2.VideoCapture(str(p))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        print('frames per second: ', fps)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        nbr_frames = int(total_frames * 0.5)\n",
    "        print('nbr_frames: ', nbr_frames)\n",
    "\n",
    "        for frame_idx in tqdm(range(total_frames)):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            ret, frame = cap.read()\n",
    "            frame_file_name = str(p.stem) + f'_{frame_idx}.jpg'\n",
    "            frame_path = str(p.parent) + frame_file_name\n",
    "            if not os.path.exists(str(frame_path)):\n",
    "                cv2.imwrite(frame_path, frame)\n",
    "    \n",
    "        cap.release()\n",
    "        if os.path.exists(str(p)):\n",
    "            os.remove(str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/volume/data/in/EmoReact/Excitement/ESCARGOT2_2.mp4\n",
      "frames per second:  23.976023976023978\n",
      "nbr_frames:  57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 115/115 [00:08<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/volume/data/in/EmoReact/Excitement/DUBSTEP140_2.mp4\n",
      "frames per second:  23.976023976023978\n",
      "nbr_frames:  35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 70/70 [00:03<00:00, 17.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/volume/data/in/EmoReact/Excitement/HARLEMSHAKE43_2.mp4\n",
      "frames per second:  23.976023976023978\n",
      "nbr_frames:  70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████████████████████████████████▉             | 116/141 [00:12<00:02,  9.33it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mextract_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[118], line 12\u001b[0m, in \u001b[0;36mextract_frames\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnbr_frames: \u001b[39m\u001b[38;5;124m'\u001b[39m, nbr_frames)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame_idx \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(total_frames)):\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCAP_PROP_POS_FRAMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     14\u001b[0m     frame_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(p\u001b[38;5;241m.\u001b[39mstem) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "extract_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_frames_needed = int(average_length * fps)\n",
    "total_frames_needed\n",
    "#sampling_rate = max(1, total_frames_needed // )  # Sample approximately 1000 frames\n",
    "\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "percentage = 0.5\n",
    "total_frames_needed = int(total_frames * percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
