{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "#from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path('/project/volume/data/in/EmoReact')\n",
    "LABELS_PATH = Path('/project/volume/data/in/EmoReact/EmoReact_V_1.0/Labels/')\n",
    "ORIG_FOLDERS = ['Test', 'Train', 'Validation']\n",
    "LABEL_FILES = ['test_labels.text', 'train_labels.text/', 'val_labels.text']\n",
    "\n",
    "labels = ['Curiosity', 'Uncertainty', 'Excitement', 'Happiness', 'Surprise', 'Disgust', 'Fear', 'Frustration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders():\n",
    "    for label in labels:\n",
    "        label_path = BASE_PATH / Path(label)\n",
    "        if not label_path.exists():\n",
    "            label_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def read_labels():\n",
    "    df_train, df_test, df_val = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "    for label in LABEL_FILES:\n",
    "        path = LABELS_PATH / Path(label)\n",
    "        df = pd.read_csv(str(path), header=None)\n",
    "        df = df.drop(columns=[df.columns[-1]])\n",
    "        df.columns = labels\n",
    "        if 'test_labels.text' in label:\n",
    "            df_train = pd.concat([df_train, df], ignore_index=True)\n",
    "        elif 'train_labels.text' in label:\n",
    "            df_test = pd.concat([df_test, df], ignore_index=True)\n",
    "        elif 'val_labels.text' in label:\n",
    "            df_val = pd.concat([df_val, df], ignore_index=True)\n",
    "\n",
    "    return df_train, df_test, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, df_val = read_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files():\n",
    "    for folder in tqdm(ORIG_FOLDERS):\n",
    "        folder_path = BASE_PATH / Path('EmoReact_V_1.0/Data') / folder\n",
    "        if 'Test' in folder:\n",
    "            df = df_test\n",
    "        elif 'Train' in folder:\n",
    "            df = df_train\n",
    "        elif 'Validation' in folder:\n",
    "            df = df_val\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for file_idx, file in enumerate(list(folder_path.rglob('*.mp4'))):\n",
    "            if file_idx >= len(df):\n",
    "                break\n",
    "            file_label = df.loc[file_idx].idxmax() \n",
    "            destination_folder = BASE_PATH / Path(file_label)\n",
    "            destination_folder.mkdir(exist_ok=True, parents=True)\n",
    "            shutil.move(str(file), str(destination_folder))\n",
    "        \n",
    "        if folder_path.exists() and folder_path.is_dir():\n",
    "            shutil.rmtree(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "move_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_lenght():\n",
    "    video_lengths = []\n",
    "    for file in list(BASE_PATH.rglob('*.mp4')):\n",
    "        cap = cv2.VideoCapture(str(file))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = frame_count / fps\n",
    "        video_lengths.append(duration)\n",
    "        cap.release()\n",
    "    return video_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_lengths = get_video_lenght()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_length = np.mean(video_lengths)\n",
    "std_dev = np.std(video_lengths)\n",
    "\n",
    "print(average_length, std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames():\n",
    "    for p in tqdm(list(BASE_PATH.rglob('*.mp4'))):\n",
    "        cap = cv2.VideoCapture(str(p))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        nbr_frames = int(total_frames * 0.25)\n",
    "        #nbr_frames = 110\n",
    "\n",
    "        for frame_idx in range(nbr_frames):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            _, frame = cap.read()\n",
    "            frame_file_name = Path(str(p.stem) + f'_{frame_idx}.jpg')\n",
    "            frame_path = str(p.parent / frame_file_name)\n",
    "            #print(frame_path)\n",
    "            if not os.path.exists(str(frame_path)):\n",
    "                cv2.imwrite(frame_path, frame)\n",
    "    \n",
    "        cap.release()\n",
    "        if os.path.exists(str(p)):\n",
    "            os.remove(str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 1037/1037 [23:45<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "extract_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe import Image\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1717402833.838333      12 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n"
     ]
    }
   ],
   "source": [
    "model_path_detect = '/project/volume/models/blaze_face_short_range.tflite'\n",
    "model_path_mesh = '/project/volume/models/face_landmarker.task'\n",
    "\n",
    "base_options_detect = python.BaseOptions(model_asset_path=model_path_detect)\n",
    "options_detect = vision.FaceDetectorOptions(base_options=base_options_detect)\n",
    "detector_detect = vision.FaceDetector.create_from_options(options_detect)\n",
    "\n",
    "base_options_mesh = python.BaseOptions(model_asset_path=model_path_mesh)\n",
    "options_mesh = vision.FaceLandmarkerOptions(base_options=base_options_mesh,\n",
    "                                       output_face_blendshapes=False,\n",
    "                                       output_facial_transformation_matrixes=True,\n",
    "                                       num_faces=1)\n",
    "detector_mesh = vision.FaceLandmarker.create_from_options(options_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 30816/30816 [17:36<00:00, 29.17it/s]\n"
     ]
    }
   ],
   "source": [
    "detect_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Number of images in total ...32074\n",
      "[INFO] Number of images used in training ... 19244 (60.0%)\n",
      "[INFO] Number of images used in testing ... 6415 (20.0%)\n",
      "[INFO] Number of images used in validation ...6415 (20.0%)\n"
     ]
    }
   ],
   "source": [
    "train_prop = 0.6\n",
    "test_prop = 0.2\n",
    "valid_prop = 0.2\n",
    "\n",
    "number_of_images = len(list(BASE_PATH.rglob('*.jpg')))\n",
    "\n",
    "print(\"[INFO] Number of images in total ...\" + str(number_of_images))\n",
    "\n",
    "n_train = int((number_of_images * train_prop) + 0.5)\n",
    "n_valid = int((number_of_images * valid_prop) + 0.5)\n",
    "n_test = number_of_images - n_train - n_valid\n",
    "\n",
    "\n",
    "print(f\"[INFO] Number of images used in training ... {str(n_train)} ({str(train_prop * 100)}%)\")\n",
    "print(f\"[INFO] Number of images used in testing ... {str(n_test)} ({str(test_prop * 100)}%)\")\n",
    "print(f\"[INFO] Number of images used in validation ...{str(n_valid)} ({str(valid_prop * 100)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_move():\n",
    "    for label in tqdm(labels):\n",
    "        folder_path = BASE_PATH / label\n",
    "        print(folder_path)\n",
    "        #print(len(list(folder_path.rglob('*.jpg'))))\n",
    "        train_destination = BASE_PATH / \"train\" / label\n",
    "        val_destination = BASE_PATH / \"val\" / label\n",
    "        test_destination = BASE_PATH / \"test\" / label\n",
    "\n",
    "        train_destination.mkdir(parents=True, exist_ok=True)\n",
    "        val_destination.mkdir(parents=True, exist_ok=True)\n",
    "        test_destination.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        files = list(folder_path.rglob('*.jpg'))\n",
    "        random.shuffle(files)\n",
    "        train_n = (int((len(files) * train_prop) + 0.5))\n",
    "        val_n = (int((len(files) * valid_prop) + 0.2))\n",
    "        \n",
    "        for file_idx, file in enumerate(list(folder_path.rglob('*.jpg'))):\n",
    "            if file_idx < train_n:\n",
    "                shutil.move(str(file), train_destination)\n",
    "            elif file_idx < train_n + val_n:\n",
    "                shutil.move(str(file), val_destination)\n",
    "            else:\n",
    "                shutil.move(str(file), test_destination)\n",
    "\n",
    "        if folder_path.exists() and folder_path.is_dir():\n",
    "            shutil.rmtree(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/volume/data/in/EmoReact/Curiosity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▍                                                                        | 1/8 [00:37<04:24, 37.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/volume/data/in/EmoReact/Uncertainty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                              | 2/8 [00:47<02:06, 21.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/volume/data/in/EmoReact/Excitement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████▏                                                   | 3/8 [01:13<01:56, 23.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/volume/data/in/EmoReact/Happiness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 4/8 [01:32<01:26, 21.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/volume/data/in/EmoReact/Surprise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████████▉                               | 5/8 [01:34<00:43, 14.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/volume/data/in/EmoReact/Disgust\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████▎                    | 6/8 [01:37<00:21, 10.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/volume/data/in/EmoReact/Fear\n",
      "/project/volume/data/in/EmoReact/Frustration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 8/8 [01:39<00:00, 12.38s/it]\n"
     ]
    }
   ],
   "source": [
    "split_and_move()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(BASE_PATH.rglob('*.jpg'))))\n",
    "\n",
    "print(14952 * 0.6)\n",
    "print(14952 * 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = keras.preprocessing.image.ImageDataGenerator()\n",
    "valid_gen = keras.preprocessing.image.ImageDataGenerator()\n",
    "test_gen = keras.preprocessing.image.ImageDataGenerator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
