{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import cv2\n",
    "    import torch\n",
    "    import torchvision\n",
    "    import sklearn.svm\n",
    "except:\n",
    "    %pip install opencv-python-headless==4.9.0.80\n",
    "    %pip install torch\n",
    "    %pip install torchvision\n",
    "    %pip install torchsummary \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import cuda\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "from PIL import Image\n",
    "\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "print('import successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "EMOREACT = Path('EmoReact')\n",
    "FER = Path('FER-2013')\n",
    "KDEF = Path('KDEF-AKDEF')\n",
    "NIMH = Path('NIMH-CHEFS')\n",
    "\n",
    "# General paths\n",
    "BASE_PATH = Path('/home/jovyan/work/data/out')\n",
    "MODEL_PATH = Path('/home/jovyan/work/models')\n",
    "\n",
    "# Set dataset here\n",
    "DATA = NIMH\n",
    "\n",
    "# Dataset-specific paths\n",
    "CURRENT_PATH = BASE_PATH / DATA\n",
    "LABELS = [f.name for f in CURRENT_PATH.iterdir() if f.is_dir()]\n",
    "IMAGE_PATHS = list(CURRENT_PATH.rglob('*.jpg'))\n",
    "\n",
    "# Constants for splitting dataset\n",
    "TRAIN = 'train'\n",
    "TEST = 'test'\n",
    "VAL = 'val'\n",
    "\n",
    "FEATURES = 'feature-extraction'\n",
    "TRANSFER = 'transfer-learning'\n",
    "FINETUNE = 'fine-tuning'\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "# CUDA\n",
    "train_on_gpu = cuda.is_available()\n",
    "print(f'[INFO] Train on gpu ...{train_on_gpu}')\n",
    "if train_on_gpu:\n",
    "    gpu_count = cuda.device_count()\n",
    "    print(f'[INFO] {gpu_count} gpus detected.')\n",
    "    if gpu_count > 1:\n",
    "        multi_gpu = True\n",
    "    else:\n",
    "        multi_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data_path, img_size, transforms=None, phase=TRAIN):\n",
    "        self.data_path = Path(data_path / phase)\n",
    "        self.img_size = img_size\n",
    "        self.transform = transforms[phase]\n",
    "        self.phase = phase\n",
    "\n",
    "        self.classes = self._get_classes()\n",
    "        self.image_paths = self._get_image_paths()\n",
    "\n",
    "\n",
    "    def _get_classes(self):\n",
    "        return [f.name for f in (self.data_path).iterdir() if f.is_dir()]\n",
    "    \n",
    "\n",
    "    def _get_image_paths(self):\n",
    "        paths = list(self.data_path.rglob('*.jpg'))\n",
    "        random.shuffle( paths )\n",
    "        return paths\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx])\n",
    "        img_path = self.image_paths[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = Path(img_path).parent.name\n",
    "\n",
    "        return img, label\n",
    "    \n",
    "\n",
    "    def show_samples(self):\n",
    "        fig = plt.figure(figsize=(20,20))\n",
    "\n",
    "        for i in range(10):\n",
    "            ax = fig.add_subplot(1, 10, i + 1)\n",
    "            _, label = self.__getitem__(i)\n",
    "            img_cv2 = self.get_cv2_img(i)\n",
    "\n",
    "            ax.imshow(img_cv2, cmap='gray')\n",
    "            ax.set_title(label)\n",
    "            ax.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def show_distribution(self):\n",
    "        labels_count = Counter([self.__getitem__(i)[1] for i in tqdm(range(len(self.image_paths)))])\n",
    "        sorted_counts = sorted(labels_count.items())\n",
    "        labels, counts = zip(*sorted_counts)\n",
    "\n",
    "        plt.figure(figsize=(10, 3))\n",
    "        bars = plt.bar(labels, counts, color='skyblue')\n",
    "        plt.xlabel(f'{DATA}')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Counts per Emotion Category')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "        for bar, count in zip(bars, counts):\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5, count,\n",
    "                    ha='center', va='bottom', color='black', fontsize=8) \n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def get_cv2_img(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        return cv2.imread(str(img_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    TRAIN: transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    VAL: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    TEST: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "datasets = {\n",
    "    x: Dataset(CURRENT_PATH, img_size=224, transforms=data_transforms, phase=x) for x in [TRAIN, VAL, TEST]\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in [TRAIN, VAL, TEST]\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    x : len(datasets[x]) for x in [TRAIN, VAL, TEST] \n",
    "}\n",
    "\n",
    "class_names = datasets[TRAIN].classes\n",
    "n_classes = len(class_names)\n",
    "total_size = sum(dataset_sizes.values())\n",
    "\n",
    "print(f\"[INFO] Total number of images ...{total_size}\")\n",
    "for x in [TRAIN, VAL, TEST]:\n",
    "    print(f\"[INFO] Number of images in {x} set ...{dataset_sizes[x]}\")\n",
    "print(\"[INFO] Number of classes: \", n_classes)\n",
    "print(\"[INFO] Classes: \", datasets[TRAIN].classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(torch.nn.Module):\n",
    "    def __init__(self, n_classes, mode=FEATURES, pretrained=True, model=16):\n",
    "        super(VGG, self).__init__()\n",
    "\n",
    "        self.conv_base = None\n",
    "        self.mode = mode\n",
    "        self.n_classes = n_classes\n",
    "        self.transfer_trained_model = None\n",
    "        self.cuda = self._check_cuda()\n",
    "\n",
    "        if model == 16:\n",
    "            self.conv_base = models.vgg16(weights='IMAGENET1K_V1')\n",
    "        elif model == 19:\n",
    "            self.conv_base = models.vgg19(weights='IMAGENET1K_V1')\n",
    "        else: \n",
    "            raise ValueError('Unsupported mode in VGG model')\n",
    "\n",
    "        # this mode removes the classifier and returns extracted features.\n",
    "        if self.mode == FEATURES:\n",
    "            for param in self.conv_base.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.conv_base.classifier = torch.nn.Identity()\n",
    "        \n",
    "        # this mode replaces the last layer of classifier-part of the vgg16 net with a custom classifier layer, which returns one of the class labels.\n",
    "        elif self.mode == TRANSFER:\n",
    "            for param in self.conv_base.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.conv_base.classifier[-1] = torch.nn.Linear(in_features=self.conv_base.classifier[-1].in_features, out_features=n_classes)\n",
    "\n",
    "        # this mode fine-tunes the classifier part and maybe also some other layers within the net??\n",
    "        elif self.mode == FINETUNE:\n",
    "            pass\n",
    "\n",
    "        else: \n",
    "            raise ValueError('Unsupported mode in VGG16 / VGG19 init')\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_base(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def summary(self):\n",
    "        summary(self.conv_base, input_size=(3, 224, 224), batch_size=batch_size, device='cuda')\n",
    "\n",
    "\n",
    "    def feature_extract(self, dataloaders):\n",
    "\n",
    "        features = np.empty((0, 25088))\n",
    "        labels = np.empty(0)\n",
    "\n",
    "        for phase in ([TRAIN, TEST, VAL]):\n",
    "\n",
    "            for inputs_batch, labels_batch in tqdm(dataloaders[phase]):\n",
    "                with torch.no_grad():\n",
    "                    features_batch = np.asarray(self.conv_base(inputs_batch))\n",
    "                    features = np.append(features, features_batch, axis=0)\n",
    "                    label = np.asarray((labels_batch)).flatten()\n",
    "\n",
    "                labels = np.append(labels, label)\n",
    "        \n",
    "        return features, labels\n",
    "    \n",
    "\n",
    "    def _check_cuda(self):\n",
    "        return torch.cuda.is_available()\n",
    "    \n",
    "\n",
    "    def transfer_learning(self):\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.conv_base.cuda()\n",
    "            \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer_ft = optim.SGD(self.conv_base.parameters(), lr=0.001, momentum=0.9)\n",
    "        exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "        return\n",
    "\n",
    "    def transfer_learning(self, dataloaders, criterion=0, optimizer=0, scheduler=0, num_epochs=10):\n",
    "\n",
    "        \n",
    "        since = time.time()\n",
    "        best_model_wts = copy.deepcopy(self.conv_base.state_dict())\n",
    "\n",
    "        best_acc = 0.0\n",
    "        avg_loss = 0\n",
    "        avg_acc = 0\n",
    "        avg_loss_val = 0\n",
    "        avg_acc_val = 0\n",
    "\n",
    "        train_batches = len(dataloaders[TRAIN])\n",
    "        val_batches = len(dataloaders[VAL])\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "            print('-' * 10)\n",
    "\n",
    "            loss_train = 0\n",
    "            loss_val = 0\n",
    "            acc_train = 0\n",
    "            acc_val = 0\n",
    "            \n",
    "            self.conv_base.train(True)\n",
    "\n",
    "            for i, data in enumerate(dataloaders[TRAIN]):\n",
    "                if i % 100 == 0:\n",
    "                    print(f\"\\rTraining batch {i}/{train_batches}\", flush=True)\n",
    "\n",
    "                if i >= train_batches / 2:\n",
    "                    break\n",
    "\n",
    "                inputs, labels = data\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    inputs, labels =inputs.cuda(), labels.cuda()\n",
    "                else:\n",
    "                    inputs, labels = inputs, labels\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.conv_base(inputs)\n",
    "\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                loss_train += loss.data[0]\n",
    "                acc_train += torch.sum(preds == labels.data)\n",
    "                \n",
    "                del inputs, labels, outputs, preds\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            print()\n",
    "            # * 2 as we only used half of the dataset\n",
    "            avg_loss = loss_train * 2 / dataset_sizes[TRAIN]\n",
    "            avg_acc = acc_train * 2 / dataset_sizes[TRAIN]\n",
    "            \n",
    "            self.conv_base.train(False)\n",
    "            self.conv_base.eval()\n",
    "\n",
    "            for i, data in enumerate(dataloaders[VAL]):\n",
    "                if i % 100 == 0:\n",
    "                    print(f\"\\rValidation batch {i}/{val_batches}\", flush=True)\n",
    "                \n",
    "                inputs, labels = data\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                else:\n",
    "                    inputs, labels = inputs, labels\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = self.conv_base(inputs)\n",
    "                \n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                loss_val += loss.data[0]\n",
    "                acc_val += torch.sum(preds == labels.data)\n",
    "                \n",
    "                del inputs, labels, outputs, preds\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            avg_loss_val = loss_val / dataset_sizes[VAL]\n",
    "            avg_acc_val = acc_val / dataset_sizes[VAL]\n",
    "\n",
    "            print()\n",
    "            print(f\"Epoch {epoch} result: \".format(epoch))\n",
    "            print(f\"Avg loss (train): {avg_loss:.4f}\")\n",
    "            print(f\"Avg acc (train): {avg_acc:.4f}\")\n",
    "            print(f\"Avg loss (val): {avg_loss_val:.4f}\")\n",
    "            print(f\"Avg acc (val): {avg_acc_val:.4f}\")\n",
    "            print('-' * 10)\n",
    "            print()\n",
    "\n",
    "            if avg_acc_val > best_acc:\n",
    "                best_acc = avg_acc_val\n",
    "                best_model_wts = copy.deepcopy(self.conv_base.state_dict())\n",
    "\n",
    "        elapsed_time = time.time() - since\n",
    "\n",
    "        print()\n",
    "        print(f\"Training completed in {elapsed_time // 60:.0f}m {elapsed_time % 60:.0f}s\")\n",
    "        print(f\"Best acc: {best_acc:.4f}\")\n",
    "\n",
    "        self.transfer_trained_model = self.conv_base.load_state_dict(best_model_wts)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "                    \n",
    "vgg16 = VGG(n_classes=n_classes, mode=FEATURES, pretrained=True, model=16)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.train_model(dataloaders=dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(vgg, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    \n",
    "        \n",
    "        \n",
    "    elapsed_time = time.time() - since\n",
    "    print()\n",
    "    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"Best acc: {:.4f}\".format(best_acc))\n",
    "    \n",
    "    vgg.load_state_dict(best_model_wts)\n",
    "    return vgg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.transfer_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(torch.nn.Module):\n",
    "    def __init__(self, n_classes, mode=FEATURES, pretrained=True):\n",
    "        super(Resnet, self).__init__()\n",
    "\n",
    "        self.conv_base = models.resnet50(weights='IMAGENET1K_V2')\n",
    "        self.mode = mode\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        if self.mode == FEATURES:\n",
    "            for param in self.conv_base.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.conv_base.fc = torch.nn.Identity()\n",
    "\n",
    "        elif self.mode == TRANSFER:\n",
    "            for param in self.conv_base.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.conv_base.fc = torch.nn.Linear(in_features=self.conv_base.classifier[-1].in_features, out_features=n_classes)\n",
    "\n",
    "        elif self.mode == FINETUNE:\n",
    "            pass\n",
    "        \n",
    "        else: \n",
    "            raise ValueError('Unsupported mode in Resnet init')\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_base(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def summary(self):\n",
    "        summary(self.conv_base, input_size=(3, 224, 224), batch_size=batch_size, device='cuda')\n",
    "\n",
    "    \n",
    "    def feature_extract(self, dataloaders):\n",
    "\n",
    "        features = np.empty((0, 2048))\n",
    "        labels = np.empty(0)\n",
    "\n",
    "        for phase in ([TRAIN, TEST, VAL]):\n",
    "\n",
    "            for inputs_batch, labels_batch in tqdm(dataloaders[phase]):\n",
    "                with torch.no_grad():\n",
    "                    features_batch = np.asarray(self.conv_base(inputs_batch))\n",
    "                    features = np.append(features, features_batch, axis=0)\n",
    "                    label = np.asarray((labels_batch)).flatten()\n",
    "\n",
    "                labels = np.append(labels, label)\n",
    "    \n",
    "        return features, labels\n",
    "    \n",
    "    def simple_classify(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = Resnet(n_classes=n_classes, mode=FEATURES, pretrained=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimhchefs = Dataset(data_path=CURRENT_PATH, img_size=64, transforms=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = resnet50.extract_features(dataloaders=dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = vgg16.extract_features(dataloaders=dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" self.linear1 = torch.nn.Linear(in_features=25088, out_features=4096, bias=True)\n",
    "self.relu1 = torch.nn.ReLU(inplace=True)\n",
    "self.dropout1 = torch.nn.Dropout(p=0.5, inplace=False)\n",
    "self.linear2 = torch.nn.Linear(in_features=4096, out_features=4096, bias=True)\n",
    "self.relu2 = torch.nn.ReLU(inplace=True)\n",
    "self.dropout2 = torch.nn.Dropout(p=0.5, inplace=False)\n",
    "self.linear3 = torch.nn.Linear(in_features=4096, out_features=n_classes, bias=True) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "for param in conv_base.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataloaders):\n",
    "\n",
    "    features = torch.zeros(0, 5)\n",
    "    labels = torch.zeros(0, dtype=torch.long)\n",
    "    i = 0\n",
    "\n",
    "    for phase in ([TRAIN, TEST, VAL]):\n",
    "\n",
    "        \n",
    "        for inputs_batch, labels_batch in tqdm(dataloaders[phase]):\n",
    "            i += 1\n",
    "            with torch.no_grad():\n",
    "                features_batch = conv_base(inputs_batch)\n",
    "                features = torch.tensor((features, features_batch))\n",
    "\n",
    "            labels = torch.tensor((labels, labels_batch))\n",
    "            return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = extract_features(dataloaders=dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = image_datasets[TRAIN].class_to_idx\n",
    "idx_to_class = { idx: class_ for class_, idx in class_to_idx.items() }\n",
    "\n",
    "print(class_to_idx)\n",
    "print(idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = {}\n",
    "for value in labels:\n",
    "    category_counts[class_names[value.item()]] = category_counts.get(class_names[value.item()], 0) + 1\n",
    "\n",
    "sorted_counts = sorted(category_counts.items(), key=lambda x: x[0])\n",
    "categories, counts = zip(*sorted_counts)\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "bars = plt.bar(categories, counts, color='skyblue')\n",
    "plt.xlabel('Emotion Category')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Counts per Emotion Category')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "for bar, count in zip(bars, counts):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5, count, ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, shuffle=True, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Number of images used in training ...\", x_train.shape[0])\n",
    "print(\"[INFO] Number of images used in testing ...\", x_test.shape[0])\n",
    "\n",
    "classifier = SVC()\n",
    "parameters = {'gamma': [0.1, 0.01, 0.001], 'C': [1, 10, 100, 1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(classifier, parameters, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_estimator = grid_search.best_estimator_\n",
    "print(\"[INFO] Best params ...\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(clf, x_train, y_train, x_test, y_test, train=True):\n",
    "    if train:\n",
    "        y_prediction = clf.predict(x_train)\n",
    "        clf_report = classification_report(y_train, y_prediction)\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, y_prediction) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, y_prediction)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        y_prediction = clf.predict(x_test)\n",
    "        clf_report = classification_report(y_test, y_prediction)\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, y_prediction) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, y_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "pickle.dump(best_estimator, open('/home/jovyan/work/model.p', 'wb'))\n",
    "\n",
    "print_score(best_estimator, x_train, y_train, x_test, y_test, train=True)\n",
    "print_score(best_estimator, x_train, y_train, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits_values = [3, 5, 10]\n",
    "\n",
    "for n_splits in n_splits_values:\n",
    "    cv = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "    scores = cross_val_score(best_estimator, features, labels, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    print(f\"{n_splits}-Fold CV: {scores.mean():.2f} accuracy with a standard deviation of {scores.std():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
