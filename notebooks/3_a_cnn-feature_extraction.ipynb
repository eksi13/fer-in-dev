{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import successful\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    import cv2\n",
    "    import torch\n",
    "    import torchvision\n",
    "    import sklearn.svm\n",
    "except:\n",
    "    %pip install opencv-python-headless==4.9.0.80\n",
    "    %pip install torch\n",
    "    %pip install torchvision\n",
    "    %pip install torchsummary \n",
    "\n",
    "import torch\n",
    "from torch import cuda\n",
    "from torchvision import transforms, datasets, models\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "print('import successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n",
      "[INFO] Train on gpu ...False\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = Path('/home/jovyan/work/data/out/KDEF-AKDEF')\n",
    "IMAGE_PATHS = list(BASE_PATH.rglob('*.jpg'))\n",
    "\n",
    "TRAIN = 'train'\n",
    "VAL = 'val'\n",
    "TEST = 'test'\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "print(Path.cwd())\n",
    "\n",
    "\n",
    "train_on_gpu = cuda.is_available()\n",
    "print(f'[INFO] Train on gpu ...{train_on_gpu}')\n",
    "if train_on_gpu:\n",
    "    gpu_count = cuda.device_count()\n",
    "    print(f'[INFO] {gpu_count} gpus detected.')\n",
    "    if gpu_count > 1:\n",
    "        multi_gpu = True\n",
    "    else:\n",
    "        multi_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Number of images in train set ...2938\n",
      "[INFO] Number of images in val set ...980\n",
      "[INFO] Number of images in test set ...980\n",
      "[INFO] Total number of images ...4898\n",
      "[INFO] Number of classes:  7\n",
      "[INFO] Classes:  ['Afraid', 'Angry', 'Disgusted', 'Happy', 'Neutral', 'Sad', 'Surprised']\n"
     ]
    }
   ],
   "source": [
    "# prepare data for feature extraction\n",
    "feature_extraction_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(\n",
    "        root=(BASE_PATH / x),\n",
    "        transform=feature_extraction_transform\n",
    "    )\n",
    "    for x in [TRAIN, VAL, TEST]\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x], \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True, \n",
    "        num_workers=4\n",
    "    )\n",
    "    for x in [TRAIN, VAL, TEST]\n",
    "}\n",
    "\n",
    "dataset_sizes = { x : len(image_datasets[x]) for x in [TRAIN, VAL, TEST] }\n",
    "class_names = image_datasets[TRAIN].classes\n",
    "n_classes = len(class_names)\n",
    "n_images = 0\n",
    "for x in [TRAIN, VAL, TEST]:\n",
    "    print(f\"[INFO] Number of images in {x} set ...{dataset_sizes[x]}\")\n",
    "    n_images += dataset_sizes[x]\n",
    "\n",
    "print(f\"[INFO] Total number of images ...{n_images}\")\n",
    "print(\"[INFO] Number of classes: \", n_classes)\n",
    "print(\"[INFO] Classes: \", image_datasets[TRAIN].classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [1, 64, 224, 224]           1,792\n",
      "              ReLU-2          [1, 64, 224, 224]               0\n",
      "            Conv2d-3          [1, 64, 224, 224]          36,928\n",
      "              ReLU-4          [1, 64, 224, 224]               0\n",
      "         MaxPool2d-5          [1, 64, 112, 112]               0\n",
      "            Conv2d-6         [1, 128, 112, 112]          73,856\n",
      "              ReLU-7         [1, 128, 112, 112]               0\n",
      "            Conv2d-8         [1, 128, 112, 112]         147,584\n",
      "              ReLU-9         [1, 128, 112, 112]               0\n",
      "        MaxPool2d-10           [1, 128, 56, 56]               0\n",
      "           Conv2d-11           [1, 256, 56, 56]         295,168\n",
      "             ReLU-12           [1, 256, 56, 56]               0\n",
      "           Conv2d-13           [1, 256, 56, 56]         590,080\n",
      "             ReLU-14           [1, 256, 56, 56]               0\n",
      "           Conv2d-15           [1, 256, 56, 56]         590,080\n",
      "             ReLU-16           [1, 256, 56, 56]               0\n",
      "        MaxPool2d-17           [1, 256, 28, 28]               0\n",
      "           Conv2d-18           [1, 512, 28, 28]       1,180,160\n",
      "             ReLU-19           [1, 512, 28, 28]               0\n",
      "           Conv2d-20           [1, 512, 28, 28]       2,359,808\n",
      "             ReLU-21           [1, 512, 28, 28]               0\n",
      "           Conv2d-22           [1, 512, 28, 28]       2,359,808\n",
      "             ReLU-23           [1, 512, 28, 28]               0\n",
      "        MaxPool2d-24           [1, 512, 14, 14]               0\n",
      "           Conv2d-25           [1, 512, 14, 14]       2,359,808\n",
      "             ReLU-26           [1, 512, 14, 14]               0\n",
      "           Conv2d-27           [1, 512, 14, 14]       2,359,808\n",
      "             ReLU-28           [1, 512, 14, 14]               0\n",
      "           Conv2d-29           [1, 512, 14, 14]       2,359,808\n",
      "             ReLU-30           [1, 512, 14, 14]               0\n",
      "        MaxPool2d-31             [1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-32             [1, 512, 7, 7]               0\n",
      "           Linear-33                  [1, 4096]     102,764,544\n",
      "             ReLU-34                  [1, 4096]               0\n",
      "          Dropout-35                  [1, 4096]               0\n",
      "           Linear-36                  [1, 4096]      16,781,312\n",
      "================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 218.71\n",
      "Params size (MB): 512.16\n",
      "Estimated Total Size (MB): 731.45\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# prepare vgg16 for feature extraction\n",
    "conv_base = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "features = list(conv_base.classifier)[:-3]\n",
    "conv_base.classifier = nn.Sequential(*features)\n",
    "summary(conv_base, input_size=(3, 224, 224), batch_size=batch_size, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Afraid': 0, 'Angry': 1, 'Disgusted': 2, 'Happy': 3, 'Neutral': 4, 'Sad': 5, 'Surprised': 6}\n",
      "{0: 'Afraid', 1: 'Angry', 2: 'Disgusted', 3: 'Happy', 4: 'Neutral', 5: 'Sad', 6: 'Surprised'}\n"
     ]
    }
   ],
   "source": [
    "class_to_idx = image_datasets[TRAIN].class_to_idx\n",
    "idx_to_class = { idx: class_ for class_, idx in class_to_idx.items() }\n",
    "\n",
    "print(class_to_idx)\n",
    "print(idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataloaders):\n",
    "\n",
    "    features = torch.zeros(0, 4096)\n",
    "    labels = torch.zeros(0, dtype=torch.long)\n",
    "    i = 0\n",
    "\n",
    "    for phase in ([TRAIN, TEST, VAL]):\n",
    "\n",
    "        \n",
    "        for inputs_batch, labels_batch in tqdm(dataloaders[phase]):\n",
    "            i += 1\n",
    "            with torch.no_grad():\n",
    "                features_batch = conv_base(inputs_batch)\n",
    "                features = torch.cat((features, features_batch))\n",
    "\n",
    "            labels = torch.cat((labels, labels_batch))\n",
    "            return features, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                | 0/2938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                | 0/2938 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "features, labels = extract_features(dataloaders=dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4096])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming labels and class_names are defined somewhere\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Use collections.Counter for counting occurrences\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[0;32m----> 5\u001b[0m category_counts \u001b[38;5;241m=\u001b[39m Counter(class_names[value\u001b[38;5;241m.\u001b[39mitem()] \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mlabels\u001b[49m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Sort categories alphabetically\u001b[39;00m\n\u001b[1;32m      8\u001b[0m sorted_counts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(category_counts\u001b[38;5;241m.\u001b[39mitems())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "category_counts = {}\n",
    "for value in labels:\n",
    "    category_counts[class_names[value.item()]] = category_counts.get(class_names[value.item()], 0) + 1\n",
    "\n",
    "sorted_counts = sorted(category_counts.items(), key=lambda x: x[0])\n",
    "categories, counts = zip(*sorted_counts)\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "bars = plt.bar(categories, counts, color='skyblue')\n",
    "plt.xlabel('Emotion Category')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Counts per Emotion Category')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "for bar, count in zip(bars, counts):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5, count, ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, shuffle=True, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Number of images used in training ... 320\n",
      "[INFO] Number of images used in testing ... 80\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Number of images used in training ...\", x_train.shape[0])\n",
    "print(\"[INFO] Number of images used in testing ...\", x_test.shape[0])\n",
    "\n",
    "classifier = SVC()\n",
    "parameters = {'gamma': [0.1, 0.01, 0.001], 'C': [1, 10, 100, 1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Best params ... {'C': 10, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(classifier, parameters, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_estimator = grid_search.best_estimator_\n",
    "print(\"[INFO] Best params ...\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(clf, x_train, y_train, x_test, y_test, train=True):\n",
    "    if train:\n",
    "        y_prediction = clf.predict(x_train)\n",
    "        clf_report = classification_report(y_train, y_prediction)\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, y_prediction) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, y_prediction)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        y_prediction = clf.predict(x_test)\n",
    "        clf_report = classification_report(y_test, y_prediction)\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, y_prediction) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, y_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      1.00      1.00        45\n",
      "           2       1.00      1.00      1.00        41\n",
      "           3       1.00      1.00      1.00        47\n",
      "           4       1.00      1.00      1.00        45\n",
      "           5       1.00      1.00      1.00        46\n",
      "           6       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       320\n",
      "   macro avg       1.00      1.00      1.00       320\n",
      "weighted avg       1.00      1.00      1.00       320\n",
      "\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[50  0  0  0  0  0  0]\n",
      " [ 0 45  0  0  0  0  0]\n",
      " [ 0  0 41  0  0  0  0]\n",
      " [ 0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0 45  0  0]\n",
      " [ 0  0  0  0  0 46  0]\n",
      " [ 0  0  0  0  0  0 46]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 21.25%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.17      0.14        12\n",
      "           1       0.18      0.17      0.17        12\n",
      "           2       0.17      0.10      0.12        10\n",
      "           3       0.29      0.33      0.31        12\n",
      "           4       0.20      0.18      0.19        11\n",
      "           5       0.38      0.27      0.32        11\n",
      "           6       0.20      0.25      0.22        12\n",
      "\n",
      "    accuracy                           0.21        80\n",
      "   macro avg       0.22      0.21      0.21        80\n",
      "weighted avg       0.22      0.21      0.21        80\n",
      "\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[2 2 0 1 2 1 4]\n",
      " [2 2 2 2 0 1 3]\n",
      " [2 2 1 2 2 0 1]\n",
      " [2 1 0 4 3 0 2]\n",
      " [3 0 2 2 2 1 1]\n",
      " [2 3 0 1 1 3 1]\n",
      " [3 1 1 2 0 2 3]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "pickle.dump(best_estimator, open('/home/jovyan/work/model.p', 'wb'))\n",
    "\n",
    "print_score(best_estimator, x_train, y_train, x_test, y_test, train=True)\n",
    "print_score(best_estimator, x_train, y_train, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Fold CV: 0.19 accuracy with a standard deviation of 0.02\n",
      "5-Fold CV: 0.20 accuracy with a standard deviation of 0.04\n",
      "10-Fold CV: 0.20 accuracy with a standard deviation of 0.07\n"
     ]
    }
   ],
   "source": [
    "n_splits_values = [3, 5, 10]\n",
    "\n",
    "for n_splits in n_splits_values:\n",
    "    cv = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "    scores = cross_val_score(best_estimator, features, labels, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    print(f\"{n_splits}-Fold CV: {scores.mean():.2f} accuracy with a standard deviation of {scores.std():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
