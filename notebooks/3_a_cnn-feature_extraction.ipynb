{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import successful\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    import cv2\n",
    "    import torch\n",
    "    import torchvision\n",
    "    import sklearn.svm\n",
    "except:\n",
    "    %pip install opencv-python-headless==4.9.0.80\n",
    "    %pip install torch\n",
    "    %pip install torchvision\n",
    "    %pip install torchsummary \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import cuda\n",
    "from torchvision import transforms, datasets, models\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "from PIL import Image\n",
    "\n",
    "print('import successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Train on gpu ...False\n"
     ]
    }
   ],
   "source": [
    "# Data paths\n",
    "EMOREACT = Path('EmoReact')\n",
    "FER = Path('FER-2013')\n",
    "KDEF = Path('KDEF-AKDEF')\n",
    "NIMH = Path('NIMH-CHEFS')\n",
    "\n",
    "# General paths\n",
    "BASE_PATH = Path('/home/jovyan/work/data/out')\n",
    "MODEL_PATH = Path('/home/jovyan/work/models')\n",
    "\n",
    "# Set dataset here\n",
    "DATA = NIMH\n",
    "\n",
    "# Dataset-specific paths\n",
    "CURRENT_PATH = BASE_PATH / DATA\n",
    "LABELS = [f.name for f in CURRENT_PATH.iterdir() if f.is_dir()]\n",
    "IMAGE_PATHS = list(CURRENT_PATH.rglob('*.jpg'))\n",
    "\n",
    "# Constants for splitting dataset\n",
    "TRAIN = 'train'\n",
    "TEST = 'test'\n",
    "VAL = 'val'\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "# CUDA\n",
    "train_on_gpu = cuda.is_available()\n",
    "print(f'[INFO] Train on gpu ...{train_on_gpu}')\n",
    "if train_on_gpu:\n",
    "    gpu_count = cuda.device_count()\n",
    "    print(f'[INFO] {gpu_count} gpus detected.')\n",
    "    if gpu_count > 1:\n",
    "        multi_gpu = True\n",
    "    else:\n",
    "        multi_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data_path, img_size, transforms=None, phase=TRAIN):\n",
    "        self.data_path = Path(data_path / phase)\n",
    "        self.img_size = img_size\n",
    "        self.transform = transforms[phase]\n",
    "        self.phase = phase\n",
    "\n",
    "        self.classes = self._get_classes()\n",
    "        self.image_paths = self._get_image_paths()\n",
    "\n",
    "\n",
    "    def _get_classes(self):\n",
    "        return [f.name for f in (self.data_path).iterdir() if f.is_dir()]\n",
    "    \n",
    "\n",
    "    def _get_image_paths(self):\n",
    "        paths = list(self.data_path.rglob('*.jpg'))\n",
    "        random.shuffle( paths )\n",
    "        return paths\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx])\n",
    "        img_path = self.image_paths[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = Path(img_path).parent.name\n",
    "\n",
    "        return img, label\n",
    "    \n",
    "\n",
    "    def show_samples(self):\n",
    "        fig = plt.figure(figsize=(20,20))\n",
    "\n",
    "        for i in range(10):\n",
    "\n",
    "            ax = fig.add_subplot(1, 10, i + 1)\n",
    "            img, label = self.__getitem__(i)\n",
    "            if img.ndim == 3:\n",
    "                img = img.squeeze(0)\n",
    "            img = img.numpy() if isinstance(img, torch.Tensor) else np.array(img)\n",
    "\n",
    "            ax.imshow(img, cmap='gray')\n",
    "            ax.set_title(label)\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def show_distribution(self):\n",
    "        labels_count = Counter([self.__getitem__(i)[1] for i in tqdm(range(len(self.image_paths)))])\n",
    "        sorted_counts = sorted(labels_count.items())\n",
    "        labels, counts = zip(*sorted_counts)\n",
    "\n",
    "        plt.figure(figsize=(10, 3))\n",
    "        bars = plt.bar(labels, counts, color='skyblue')\n",
    "        plt.xlabel(f'{DATA}')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Counts per Emotion Category')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "        for bar, count in zip(bars, counts):\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5, count,\n",
    "                    ha='center', va='bottom', color='black', fontsize=8) \n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def get_cv2_img(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        return cv2.imread(str(img_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Total number of images ...533\n",
      "[INFO] Number of images in train set ...320\n",
      "[INFO] Number of images in val set ...106\n",
      "[INFO] Number of images in test set ...107\n",
      "[INFO] Number of classes:  5\n",
      "[INFO] Classes:  ['Happy', 'Sad', 'Neutral', 'Angry', 'Afraid']\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    TRAIN: transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    VAL: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    TEST: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "datasets = {\n",
    "    x: Dataset(CURRENT_PATH, img_size=224, transforms=data_transforms, phase=x) for x in [TRAIN, VAL, TEST]\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in [TRAIN, VAL, TEST]\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    x : len(datasets[x]) for x in [TRAIN, VAL, TEST] \n",
    "}\n",
    "\n",
    "class_names = datasets[TRAIN].classes\n",
    "n_classes = len(class_names)\n",
    "total_size = sum(dataset_sizes.values())\n",
    "\n",
    "print(f\"[INFO] Total number of images ...{total_size}\")\n",
    "for x in [TRAIN, VAL, TEST]:\n",
    "    print(f\"[INFO] Number of images in {x} set ...{dataset_sizes[x]}\")\n",
    "print(\"[INFO] Number of classes: \", n_classes)\n",
    "print(\"[INFO] Classes: \", datasets[TRAIN].classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(in_features=25088, out_features=4096, bias=True)\n",
    "        self.relu1 = torch.nn.ReLU(inplace=True)\n",
    "        self.dropout1 = torch.nn.Dropout(p=0.5, inplace=False)\n",
    "        self.linear2 = torch.nn.Linear(in_features=4096, out_features=4096, bias=True)\n",
    "        self.relu2 = torch.nn.ReLU(inplace=True)\n",
    "        self.dropout2 = torch.nn.Dropout(p=0.5, inplace=False)\n",
    "        self.linear3 = torch.nn.Linear(in_features=4096, out_features=n_classes, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "conv_base = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "simple_cls = SimpleClassifier()\n",
    "conv_base.classifier = simple_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary(conv_base, input_size=(3, 224, 224), batch_size=batch_size, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Freeze the pre-trained parameters\n",
    "for param in conv_base.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the classifier with your TinyModel\n",
    "vgg16.classifier = TinyModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = image_datasets[TRAIN].class_to_idx\n",
    "idx_to_class = { idx: class_ for class_, idx in class_to_idx.items() }\n",
    "\n",
    "print(class_to_idx)\n",
    "print(idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataloaders):\n",
    "\n",
    "    features = torch.zeros(0, 4096)\n",
    "    labels = torch.zeros(0, dtype=torch.long)\n",
    "    i = 0\n",
    "\n",
    "    for phase in ([TRAIN, TEST, VAL]):\n",
    "\n",
    "        \n",
    "        for inputs_batch, labels_batch in tqdm(dataloaders[phase]):\n",
    "            i += 1\n",
    "            with torch.no_grad():\n",
    "                features_batch = conv_base(inputs_batch)\n",
    "                features = torch.cat((features, features_batch))\n",
    "\n",
    "            labels = torch.cat((labels, labels_batch))\n",
    "            return features, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = extract_features(dataloaders=dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = {}\n",
    "for value in labels:\n",
    "    category_counts[class_names[value.item()]] = category_counts.get(class_names[value.item()], 0) + 1\n",
    "\n",
    "sorted_counts = sorted(category_counts.items(), key=lambda x: x[0])\n",
    "categories, counts = zip(*sorted_counts)\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "bars = plt.bar(categories, counts, color='skyblue')\n",
    "plt.xlabel('Emotion Category')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Counts per Emotion Category')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "for bar, count in zip(bars, counts):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5, count, ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, shuffle=True, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Number of images used in training ...\", x_train.shape[0])\n",
    "print(\"[INFO] Number of images used in testing ...\", x_test.shape[0])\n",
    "\n",
    "classifier = SVC()\n",
    "parameters = {'gamma': [0.1, 0.01, 0.001], 'C': [1, 10, 100, 1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(classifier, parameters, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_estimator = grid_search.best_estimator_\n",
    "print(\"[INFO] Best params ...\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(clf, x_train, y_train, x_test, y_test, train=True):\n",
    "    if train:\n",
    "        y_prediction = clf.predict(x_train)\n",
    "        clf_report = classification_report(y_train, y_prediction)\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, y_prediction) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, y_prediction)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        y_prediction = clf.predict(x_test)\n",
    "        clf_report = classification_report(y_test, y_prediction)\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, y_prediction) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, y_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "pickle.dump(best_estimator, open('/home/jovyan/work/model.p', 'wb'))\n",
    "\n",
    "print_score(best_estimator, x_train, y_train, x_test, y_test, train=True)\n",
    "print_score(best_estimator, x_train, y_train, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits_values = [3, 5, 10]\n",
    "\n",
    "for n_splits in n_splits_values:\n",
    "    cv = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "    scores = cross_val_score(best_estimator, features, labels, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    print(f\"{n_splits}-Fold CV: {scores.mean():.2f} accuracy with a standard deviation of {scores.std():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
