{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a492c6b3-1386-4aed-87e0-a999d9e13118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import successfull\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import cv2\n",
    "except:\n",
    "    %pip install opencv-python-headless==4.9.0.80\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import shutil\n",
    "\n",
    "print('import successfull')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592003e7-ec55-447b-b2a9-e3823dd82796",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53083bc1-71e6-4175-9995-719fc84667f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = Path('/home/jovyan/work/videos/')\n",
    "VIDEO_PATHS = list(BASE_PATH.rglob('*.MP4')) + list(BASE_PATH.rglob('*.mp4'))\n",
    "CSV_PATHS = list(BASE_PATH.rglob('*.csv'))\n",
    "\n",
    "T1_PATHS_str = [str(file) for file in VIDEO_PATHS if not re.search('gelöschte|clipped|T2|cut|S18', str(file))]\n",
    "T1_PATHS = [Path(file) for file in T1_PATHS_str]\n",
    "\n",
    "#T2_PATHS_str = [str(file) for file in VIDEO_PATHS if not re.search('gelöschte|clipped|T1', str(file))]\n",
    "#T2_PATHS = [Path(file) for file in T2_PATHS_str]\n",
    "\n",
    "\n",
    "ELAN = '_ELAN'\n",
    "SYNC = '_sync'\n",
    "\n",
    "idx_category = {\n",
    "    0.0: 'neutral',\n",
    "    1.1: 'negative',\n",
    "    1.2: 'positive'\n",
    "}\n",
    "category_idx = {\n",
    "    'neutral': 0.0,\n",
    "    'negative': 1.1, \n",
    "    'positive': 1.2\n",
    "}\n",
    "\n",
    "print(len(T1_PATHS))\n",
    "#print(len(T2_PATHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b411ef9-e350-4ecf-9c71-79fb4c603f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_PATHS_str.sort()\n",
    "T1_PATHS_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87b6f293-29e0-4f7f-b718-375444f01e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179/179 [00:00<00:00, 367.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved file into: /home/jovyan/work/output/files.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 175/175 [00:00<00:00, 1597.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved file into: /home/jovyan/work/output/files.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:01<00:00, 106.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved file into: /home/jovyan/work/output/files.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "files_dict = find_files()\n",
    "files_dict = get_times(files_dict)\n",
    "files_dict = get_analysis(files_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "59dd6388-9095-425f-8794-a03d5d260121",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_dict = {\n",
    "    'START_S001_T1_La1': \"16:30:56\",\n",
    "    'START_S001_T1_La2': \"16:55:21\",\n",
    "    'START_S001_T1_LaCon_Ki': \"17:12:57\",\n",
    "    'START_S001_T1_LaCon_Mu': \"17:22:38\",\n",
    "\n",
    "    'START_S002_T1': \"16:59:00\",\n",
    "    'START_S002_T1_La1': \"00:00:00\",\n",
    "    'START_S002_T1_La2': \"00:00:00\",\n",
    "    \n",
    "    'START_S004_T1_La1': \"00:00:00\",\n",
    "    'START_S004_T1_La2':  \"00:00:00\",\n",
    "    'START_S004_T1_LaCon_Ki':  \"00:00:00\",\n",
    "    'START_S004_T1_LaCon_Mu':  \"00:00:00\",\n",
    "    \n",
    "    'START_S005_T1_La1':  \"17:12:00\",\n",
    "    'START_S005_T1_La2':  \"00:00:00\",\n",
    "    'START_S005_T1_LaCon_Ki':  \"00:00:00\",\n",
    "    'START_S005_T1_LaCon_Mu_cut':  \"00:00:00\",\n",
    "    \n",
    "    'START_S006_T1_La1': \"15:06:05\",\n",
    "    'START_S006_T1_La2': \"15:28:55\",\n",
    "    'START_S006_T1_LaCon_Ki': \"15:48:04\",\n",
    "    'START_S006_T1_LaCon_Mu': \"15:55:54\",\n",
    "    \n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e1df902a-9e93-45e9-b58f-283449cb0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def save_image(path, img):\n",
    "    cv2.imwrite(path, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9519bfc4-ff45-44e6-845d-ae23d4501d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(files_dict, times_dict):\n",
    "    for file, file_info in tqdm(files_dict.items()):\n",
    "        # init cv2 parameters\n",
    "        cap = cv2.VideoCapture(str(file_info['path']))        \n",
    "        fps, num_frames = int(cap.get(cv2.CAP_PROP_FPS)), int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        # set output directories for saving\n",
    "        output_dir = Path(f'/home/jovyan/work/output/frames/{file}')\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "        # time stamp computations\n",
    "        start_time = datetime.strptime(file_info['start_time'], '%H:%M:%f').time()\n",
    "        video_time = datetime.strptime(times_dict[file], '%H:%M:%S').time()\n",
    "        \n",
    "        if not video_time == datetime.strptime('00:00:00', '%H:%M:%S').time():\n",
    "            start_datetime = datetime.combine(datetime.today(), start_time)\n",
    "            video_datetime = datetime.combine(datetime.today(), video_time)\n",
    "            diff = (start_datetime - video_datetime).seconds\n",
    "        else: \n",
    "            diff = 0\n",
    "        start_idx = int(fps*diff)\n",
    "    \n",
    "        # get analysis file\n",
    "        if 'analysis_file' in file_info and file_info['analysis_file']:\n",
    "            df = pd.read_csv(file_info['analysis_file'])\n",
    "\n",
    "            df = pd.read_csv(file_info['analysis_file'])\n",
    "            df = df[['timestamp_start_short', 'label']]\n",
    "        \n",
    "            # extract frames for timestamps from analysis file\n",
    "            for index, (timestamp, label) in df.iterrows():\n",
    "                frame_idx = start_idx + int(timestamp * fps)\n",
    "                if frame_idx >= num_frames:\n",
    "                    break\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "                _, frame = cap.read()\n",
    "                res_path = str(output_dir / f'{file}_F{index}_T{timestamp}_L{label}.jpg')\n",
    "                save_image(res_path, frame)\n",
    "        else:\n",
    "            pass   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b06c3c-800f-45df-9d87-d0cf51924ec6",
   "metadata": {},
   "source": [
    "# AB HIER QUATSCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4eccda8e-fc39-4ff0-872a-24e08cc4efee",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 15) (4091518770.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[178], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    'Ki_df: ''\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 15)\n"
     ]
    }
   ],
   "source": [
    "def process_files(video_paths=T1_PATHS):\n",
    "    meta_dict = {}\n",
    "    \n",
    "    for video_path in tqdm(video_paths):\n",
    "        name = video_path.stem\n",
    "        folder = video_path.parent.parent\n",
    "        \n",
    "        meta_dict[str(name)] = {\n",
    "            'path': str(video_path),\n",
    "            'start_end_file': \"\",\n",
    "            'sync_file': \"\",\n",
    "            'start_time': '00:00:00',\n",
    "            'end_time': '00:00:00',\n",
    "            'Mu_df': '',\n",
    "            'Ki_df: ''\n",
    "        } \n",
    "        \n",
    "        # set output path\n",
    "        destination_folder = Path('/home/jovyan/work/output/') / name\n",
    "        \n",
    "        # search for timestamp csv & move to folder\n",
    "        csvs = [str(x) for x in folder.iterdir() if x.is_file() and x.suffix == '.csv']\n",
    "        match_csv = [file for file in csvs if re.search(name, file)]\n",
    "        match_csv = match_csv[0] if match_csv else None\n",
    "\n",
    "        videoanalyse_folder = Path(folder / 'Videoanalyse')\n",
    "        if videoanalyse_folder.exists() and videoanalyse_folder.is_dir():\n",
    "            # search for analysis txt file and move to folder\n",
    "            txt_name = name[:13] + ELAN + name[13:] + SYNC\n",
    "            txts = [str(x) for x in videoanalyse_folder.iterdir() if x.is_file() and x.suffix == '.txt']\n",
    "            match_txt = [file for file in txts if re.search(txt_name, file)]\n",
    "            match_txt = match_txt[0] if match_txt else None\n",
    "\n",
    "        # only create output if both files exist\n",
    "        if match_csv and match_txt: \n",
    "            destination_folder.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            shutil.copy(match_csv, str(destination_folder))\n",
    "            meta_dict[str(name)]['start_end_file'] = str(destination_folder) + '/' + str(Path(match_csv).name)\n",
    "            shutil.copy(match_txt, str(destination_folder))\n",
    "            meta_dict[str(name)]['sync_file'] = str(destination_folder) + '/' + str(Path(match_txt).name)\n",
    "        \n",
    "        # delete if some file do not exist\n",
    "        if str(name) in meta_dict and meta_dict[str(name)]['sync_file'] == \"\":\n",
    "                del meta_dict[str(name)]\n",
    "    \n",
    "    # save json\n",
    "    json_file = '/home/jovyan/work/output/meta_file.json'\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(meta_dict, f, indent=4)\n",
    "        \n",
    "    return meta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b0f029-b8da-41c7-9aea-4514b667e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_times(file_dict=file_dict):\n",
    "    # adapt start and end times\n",
    "    for (file, file_info) in tqdm(file_dict.items()):\n",
    "        se_file = file_dict[str(file)]['start_end_file']\n",
    "        if se_file:\n",
    "            df = pd.read_csv(se_file)\n",
    "            file_dict[str(file)]['start_time'] = f\"{df.iloc[0]['hour']}:{df.iloc[0]['minute']}:{df.iloc[0]['milisecond']}\"\n",
    "            file_dict[str(file)]['end_time'] = f\"{df.iloc[1]['hour']}:{df.iloc[1]['minute']}:{df.iloc[1]['milisecond']}\"\n",
    "   \n",
    "    # save json\n",
    "    json_file = '/home/jovyan/work/output/meta_file.json'\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(file_dict, f, indent=4)\n",
    "    return file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2de249e9-eed7-403a-a2c6-9a4a16afbbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_analysis(file_dict=time_dict):\n",
    "    for (file, file_info) in tqdm(file_dict.items()):\n",
    "        sync_file = file_dict[str(name)]['sync_file']\n",
    "        if sync_file:\n",
    "            df = pd.read_csv(sync_file, sep=\"\t\", header=None)\n",
    "            if(len(df.columns) >= 10):\n",
    "                df = df.drop(df.columns[-1], axis=1)\n",
    "            columns = ['category', 'file', 'timestamp_start_long', \n",
    "                       'timestamp_start_short', 'timestamp_end_long', 'timestamp_end_short', \n",
    "                       'length_long', 'length_short', 'label']\n",
    "            df.columns = columns\n",
    "            # create df for both mother and child and save to output\n",
    "            mu_df = filtered_df[filtered_df['category'].str.contains('SE_Mu')].reset_index(drop=True)\n",
    "            ki_df = filtered_df[filtered_df['category'].str.contains('SE_Ki')].reset_index(drop=True)\n",
    "\n",
    "            output_dir = Path('/home/jovyan/work/output/' + file)\n",
    "            output_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            mu_path = str(output_dir) + '/MU_DF.csv'\n",
    "            ki_path = str(output_dir) + '/MI_DF.csv'\n",
    "            \n",
    "            mu_df.to_csv(mu_path, index=False)\n",
    "            ki_df.to_csv(ki_path, index=False)    \n",
    "\n",
    "            file_dict[str(file)]['Mu_df'] = mu_path\n",
    "            file_dict[str(file)]['Ki_df'] = ki_path\n",
    "\n",
    "        # save json\n",
    "        json_file = '/home/jovyan/work/output/meta_file.json'\n",
    "        with open(json_file, 'w') as f:\n",
    "            json.dump(file_dict, f, indent=4)\n",
    "        return file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2df19c2f-f031-4450-acc0-3d7883cc9393",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (4129195882.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[190], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    file_dict[str(file)]['path'] = str(destination_folder / Path(video_path).name))\u001b[0m\n\u001b[0m                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "def move_videos(file_dict=file_dict):\n",
    "    for (file, file_info) in tqdm(file_dict.items()):\n",
    "        \n",
    "        video_path = file_dict[str(file)]['path']\n",
    "        destination_folder = Path('/home/jovyan/work/output/') / Path(file).name\n",
    "        \n",
    "        shutil.copy(video_path, str(destination_folder))\n",
    "\n",
    "        file_dict[str(file)]['path'] = str(destination_folder / Path(video_path).name))\n",
    "        \n",
    "        # save json\n",
    "    json_file = '/home/jovyan/work/output/meta_file.json'\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(file_dict, f, indent=4)\n",
    "    return file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b9f1775c-4c0f-4fca-8ac0-485aaee3c926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179/179 [00:18<00:00,  9.94it/s]\n"
     ]
    }
   ],
   "source": [
    "file_dict = process_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b2019b9e-a3d7-499b-8bc9-3caa07e9b696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:00<00:00, 232.37it/s]\n"
     ]
    }
   ],
   "source": [
    "file_dict = process_times()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3e490605-9271-4e1d-b384-bf6c2080c716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:01<00:00, 52.06it/s]\n"
     ]
    }
   ],
   "source": [
    "process_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "23a3ae3c-9ddd-43b7-a1e6-1ea39724b8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/87 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/output/START_S001_T1_La1/START_S001_T1_La1.MP4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "move_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1183c88-44d4-4897-b458-6b2770b8d779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(files_dict=time, times_dict):\n",
    "    for (file, file_info) in tqdm(files_dict.items()):\n",
    "        # init cv2 parameters\n",
    "        cap = cv2.VideoCapture(str(file_info['path']))        \n",
    "        fps, num_frames = int(cap.get(cv2.CAP_PROP_FPS)), int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        # set output directories for saving\n",
    "        output_dir = Path(f'/home/jovyan/work/output/frames/{file}')\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "        # time stamp computations\n",
    "        start_time = datetime.strptime(file_info['start_time'], '%H:%M:%f').time()\n",
    "        video_time = datetime.strptime(times_dict[file], '%H:%M:%S').time()\n",
    "        \n",
    "        if not video_time == datetime.strptime('00:00:00', '%H:%M:%S').time():\n",
    "            start_datetime = datetime.combine(datetime.today(), start_time)\n",
    "            video_datetime = datetime.combine(datetime.today(), video_time)\n",
    "            diff = (start_datetime - video_datetime).seconds\n",
    "        else: \n",
    "            diff = 0\n",
    "        start_idx = int(fps*diff)\n",
    "    \n",
    "        # get analysis file\n",
    "        if 'analysis_file' in file_info and file_info['analysis_file']:\n",
    "            df = pd.read_csv(file_info['analysis_file'])\n",
    "\n",
    "            df = pd.read_csv(file_info['analysis_file'])\n",
    "            df = df[['timestamp_start_short', 'label']]\n",
    "        \n",
    "            # extract frames for timestamps from analysis file\n",
    "            for index, (timestamp, label) in df.iterrows():\n",
    "                frame_idx = start_idx + int(timestamp * fps)\n",
    "                if frame_idx >= num_frames:\n",
    "                    break\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "                _, frame = cap.read()\n",
    "                res_path = str(output_dir / f'{file}_F{index}_T{timestamp}_L{label}.jpg')\n",
    "                save_image(res_path, frame)\n",
    "        else:\n",
    "            pass   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
