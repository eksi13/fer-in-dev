{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a492c6b3-1386-4aed-87e0-a999d9e13118",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import cv2\n",
    "except:\n",
    "    %pip install opencv-python-headless==4.9.0.80\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import shutil\n",
    "\n",
    "print('import successfull')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592003e7-ec55-447b-b2a9-e3823dd82796",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53083bc1-71e6-4175-9995-719fc84667f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path('/home/jovyan/work/videos/')\n",
    "VIDEO_PATHS = list(BASE_PATH.rglob('*.MP4')) + list(BASE_PATH.rglob('*.mp4'))\n",
    "CSV_PATHS = list(BASE_PATH.rglob('*.csv'))\n",
    "\n",
    "T1_PATHS_str = [str(file) for file in VIDEO_PATHS if not re.search('gelöschte|clipped|T2|cut|S18', str(file))]\n",
    "T1_PATHS = [Path(file) for file in T1_PATHS_str]\n",
    "\n",
    "#T2_PATHS_str = [str(file) for file in VIDEO_PATHS if not re.search('gelöschte|clipped|T1', str(file))]\n",
    "#T2_PATHS = [Path(file) for file in T2_PATHS_str]\n",
    "\n",
    "\n",
    "ELAN = '_ELAN'\n",
    "SYNC = '_sync'\n",
    "\n",
    "idx_category = {\n",
    "    0.0: 'neutral',\n",
    "    1.1: 'negative',\n",
    "    1.2: 'positive'\n",
    "}\n",
    "category_idx = {\n",
    "    'neutral': 0.0,\n",
    "    'negative': 1.1, \n",
    "    'positive': 1.2\n",
    "}\n",
    "\n",
    "print(len(T1_PATHS))\n",
    "#print(len(T2_PATHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65535c19-b2fe-423b-986f-4682f6abe025",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'path'\n",
    "TIME_FILE = 'start_end_file'\n",
    "SYNC_FILE = 'sync_file'\n",
    "START = 'start_time'\n",
    "END = 'end_time'\n",
    "MU = 'Mu_df'\n",
    "KI = 'Ki_df'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b06c3c-800f-45df-9d87-d0cf51924ec6",
   "metadata": {},
   "source": [
    "# AB HIER QUATSCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eccda8e-fc39-4ff0-872a-24e08cc4efee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(video_paths=T1_PATHS):\n",
    "    meta_dict = {}\n",
    "    \n",
    "    for video_path in tqdm(video_paths):\n",
    "        name = video_path.stem\n",
    "        folder = video_path.parent.parent\n",
    "        \n",
    "        meta_dict[str(name)] = {\n",
    "            'path': str(video_path),\n",
    "            'start_end_file': \"\",\n",
    "            'sync_file': \"\",\n",
    "            'start_time': '00:00:00',\n",
    "            'end_time': '00:00:00',\n",
    "            'Mu_df': '',\n",
    "            'Ki_df': ''\n",
    "        } \n",
    "        \n",
    "        # set output path\n",
    "        destination_folder = Path('/home/jovyan/work/output/') / name\n",
    "        \n",
    "        # search for timestamp csv & move to folder\n",
    "        csvs = [str(x) for x in folder.iterdir() if x.is_file() and x.suffix == '.csv']\n",
    "        match_csv = [file for file in csvs if re.search(name, file)]\n",
    "        match_csv = match_csv[0] if match_csv else None\n",
    "\n",
    "        videoanalyse_folder = Path(folder / 'Videoanalyse')\n",
    "        if videoanalyse_folder.exists() and videoanalyse_folder.is_dir():\n",
    "            # search for analysis txt file and move to folder\n",
    "            txt_name = name[:13] + ELAN + name[13:] + SYNC\n",
    "            txts = [str(x) for x in videoanalyse_folder.iterdir() if x.is_file() and x.suffix == '.txt']\n",
    "            match_txt = [file for file in txts if re.search(txt_name, file)]\n",
    "            match_txt = match_txt[0] if match_txt else None\n",
    "\n",
    "        # only create output if both files exist\n",
    "        if match_csv and match_txt: \n",
    "            destination_folder.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            shutil.copy(match_csv, str(destination_folder))\n",
    "            meta_dict[str(name)]['start_end_file'] = str(destination_folder) + '/' + str(Path(match_csv).name)\n",
    "            shutil.copy(match_txt, str(destination_folder))\n",
    "            meta_dict[str(name)]['sync_file'] = str(destination_folder) + '/' + str(Path(match_txt).name)\n",
    "        \n",
    "        # delete if some file do not exist\n",
    "        if str(name) in meta_dict and meta_dict[str(name)]['sync_file'] == \"\":\n",
    "                del meta_dict[str(name)]\n",
    "    \n",
    "    # save json\n",
    "    json_file = '/home/jovyan/work/output/meta_file.json'\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(meta_dict, f, indent=4)\n",
    "        \n",
    "    return meta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b0f029-b8da-41c7-9aea-4514b667e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_times(file_dict):\n",
    "    # adapt start and end times\n",
    "    for (file, file_info) in tqdm(file_dict.items()):\n",
    "        se_file = file_dict[str(file)]['start_end_file']\n",
    "        if se_file:\n",
    "            df = pd.read_csv(se_file)\n",
    "            file_dict[str(file)]['start_time'] = f\"{df.iloc[0]['hour']}:{df.iloc[0]['minute']}:{df.iloc[0]['milisecond']}\"\n",
    "            file_dict[str(file)]['end_time'] = f\"{df.iloc[1]['hour']}:{df.iloc[1]['minute']}:{df.iloc[1]['milisecond']}\"\n",
    "   \n",
    "    # save json\n",
    "    json_file = '/home/jovyan/work/output/meta_file.json'\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(file_dict, f, indent=4)\n",
    "    return file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de249e9-eed7-403a-a2c6-9a4a16afbbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_analysis(file_dict):\n",
    "    local_dict = file_dict\n",
    "    for (file, file_info) in tqdm(local_dict.items()):        \n",
    "        sync_file = local_dict[str(file)][SYNC_FILE]\n",
    "        if sync_file:\n",
    "            df = pd.read_csv(sync_file, sep=\"\t\", header=None)\n",
    "            if(len(df.columns) >= 10):\n",
    "                df = df.drop(df.columns[-1], axis=1)\n",
    "            columns = ['category', 'file', 'timestamp_start_long', \n",
    "                       'timestamp_start_short', 'timestamp_end_long', 'timestamp_end_short', \n",
    "                       'length_long', 'length_short', 'label']\n",
    "            df.columns = columns\n",
    "            # create df for both mother and child and save to output\n",
    "            filtered_df = df[df['category'].str.contains('SE')].reset_index(drop=True)\n",
    "            mu_df = filtered_df[filtered_df['category'].str.contains('Mu')].reset_index(drop=True)\n",
    "            ki_df = filtered_df[filtered_df['category'].str.contains('Ki')].reset_index(drop=True)\n",
    "\n",
    "            output_dir = Path('/home/jovyan/work/output/' + file)\n",
    "            output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            mu_path = str(output_dir) + '/MU_DF.csv'\n",
    "            ki_path = str(output_dir) + '/KI_DF.csv'\n",
    "            \n",
    "            mu_df.to_csv(mu_path, index=False)\n",
    "            ki_df.to_csv(ki_path, index=False)\n",
    "\n",
    "            local_dict[str(file)][MU] = mu_path\n",
    "            local_dict[str(file)][KI] = ki_path\n",
    "\n",
    "    # save json\n",
    "    json_file = '/home/jovyan/work/output/meta_file.json'\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(local_dict, f, indent=4)\n",
    "    \n",
    "    return local_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df19c2f-f031-4450-acc0-3d7883cc9393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_videos(file_dict):\n",
    "    for (file, file_info) in tqdm(file_dict.items()):\n",
    "        \n",
    "        video_path = file_dict[str(file)]['path']\n",
    "        destination_folder = Path('/home/jovyan/work/output/') / Path(file).name\n",
    "        \n",
    "        shutil.copy(video_path, str(destination_folder))\n",
    "\n",
    "        file_dict[str(file)]['path'] = str(destination_folder / Path(video_path).name)\n",
    "        \n",
    "        # save json\n",
    "    json_file = '/home/jovyan/work/output/meta_file.json'\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(file_dict, f, indent=4)\n",
    "    return file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f1775c-4c0f-4fca-8ac0-485aaee3c926",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = process_files()\n",
    "file_dict = process_times(file_dict)\n",
    "file_dict = process_analysis(file_dict)\n",
    "file_dict = move_videos(file_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18113f6-30e8-467f-8387-3a0767901c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file constants\n",
    "time_path = '/home/jovyan/work/output/time_dict.json'\n",
    "meta_path = '/home/jovyan/work/output/meta_file.json'\n",
    "\n",
    "# misc\n",
    "name = 'START_S001_T1_La1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49706ee-670a-434b-8f03-b76fa560827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3611398-29f6-43b6-ab69-0fc960d3affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(time_path, meta_path, file_dict):\n",
    "    for file, file_info in tqdm(file_dict.items()):   \n",
    "        #file = 'START_S010_T1_La1'\n",
    "        #print(file)\n",
    "        with open(time_path) as f:\n",
    "            time_dict = json.load(f)\n",
    "\n",
    "        with open(meta_path) as f:\n",
    "            meta_file = json.load(f)\n",
    "        \n",
    "        # set up output path for saving\n",
    "        output_dir = Path(f'/home/jovyan/work/output/frames/{file}')\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        #print(meta_file[file][START])\n",
    "        # compute time difference between start of experiment and video start time\n",
    "        start_time = datetime.datetime.strptime(meta_file[file][START], '%H:%M:%f').replace(microsecond=0)\n",
    "        start_time = datetime.time(start_time.hour, start_time.minute, int(start_time.strftime('%H:%M:%S:%f')[-6:-4]))\n",
    "        start_time = datetime.datetime.combine(datetime.date(1900, 1, 1), start_time)\n",
    "        video_time = datetime.datetime.strptime(time_dict[file], '%H:%M:%S')\n",
    "\n",
    "        #print(start_time)\n",
    "        #print(video_time)\n",
    "        \n",
    "        if start_time <= video_time:\n",
    "            diff = 0\n",
    "        elif not video_time.time() == datetime.datetime.strptime('00:00:00', '%H:%M:%S').time():\n",
    "            diff = (start_time - video_time).seconds\n",
    "        else:\n",
    "            diff = 0\n",
    "\n",
    "        #print(diff)\n",
    "        #return\n",
    "\n",
    "        # set up cv2 things\n",
    "        cap = cv2.VideoCapture(str(meta_file[file][PATH])) \n",
    "        fps, num_frames = int(cap.get(cv2.CAP_PROP_FPS)), int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # beginnning of experiment frame index\n",
    "        start_idx = int(fps*diff)\n",
    "        \n",
    "        # get the event dfs\n",
    "        ki_df = pd.read_csv(meta_file[file][KI])\n",
    "        mu_df = pd.read_csv(meta_file[file][MU])\n",
    "        \n",
    "        ki_df_short = ki_df[['timestamp_start_short', 'label']]\n",
    "        mu_df_short = mu_df[['timestamp_start_short', 'label']]\n",
    "        \n",
    "        for index, (ki_row, mu_row) in enumerate(zip(ki_df_short.iterrows(), mu_df_short.iterrows())):\n",
    "            # access df data\n",
    "            _, ki_data = ki_row\n",
    "            _, mu_data = mu_row\n",
    "            ki_timestamp, ki_label = ki_data['timestamp_start_short'], ki_data['label']\n",
    "            mu_timestamp, mu_label = mu_data['timestamp_start_short'], mu_data['label']\n",
    "        \n",
    "            # getframe of start of experiment\n",
    "            frame_idx = int(start_idx + int(ki_timestamp * fps))\n",
    "            if frame_idx >= num_frames:\n",
    "                break\n",
    "                \n",
    "            # set up cv2 stuff\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            _, frame = cap.read()\n",
    "            res_path = str(output_dir / f'{file}_frame_{index}_timestamp_{ki_timestamp}_MU_{mu_label}_KI_{ki_label}.jpg')\n",
    "            cv2.imwrite(res_path, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2524469d-a7ca-4303-98be-da40e4352700",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_frames(time_path, meta_path, file_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47d6564-549e-4f66-b28b-5df45590bb7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
