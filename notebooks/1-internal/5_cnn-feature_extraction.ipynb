{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import cv2\n",
    "    import torch\n",
    "    import torchvision\n",
    "    import sklearn.svm\n",
    "except:\n",
    "    %pip install opencv-python-headless==4.9.0.80\n",
    "    %pip install torch\n",
    "    %pip install torchvision\n",
    "    %pip install torchsummary \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import cuda\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import pickle \n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "from torchsummary import summary\n",
    "from PIL import Image\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "print('import successful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove checkpoints\n",
    "checkpoints = list(Path('/home/jovyan/work').rglob('.ipynb_checkpoints'))\n",
    "\n",
    "for file in checkpoints:\n",
    "    if file.is_dir():        \n",
    "        for sub_file in file.iterdir():\n",
    "            if sub_file.is_file():\n",
    "                sub_file.unlink()\n",
    "            elif sub_file.is_dir():\n",
    "                sub_file.rmdir()\n",
    "    file.rmdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('/home/jovyan/work/output/extracted_faces')\n",
    "MODEL_PATH = Path('/home/jovyan/work/models')\n",
    "\n",
    "TRAIN = 'train'\n",
    "TEST = 'test'\n",
    "VAL = 'val'\n",
    "\n",
    "LABELS = [f.name for f in (PATH / TRAIN).iterdir() if f.is_dir()]\n",
    "IMAGES = list(PATH.rglob('*.jpg'))\n",
    "\n",
    "NEG = [str(file) for file in IMAGES if re.search('_1.1.jpg', str(file))]\n",
    "POS = [str(file) for file in IMAGES if re.search('_1.2.jpg', str(file))]\n",
    "NEU = [str(file) for file in IMAGES if re.search('_0.0.jpg', str(file))]\n",
    "\n",
    "NUM_IMAGES = len(IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(NEG), len(POS), len(NEU))\n",
    "\n",
    "random.shuffle(NEG)\n",
    "random.shuffle(POS)\n",
    "random.shuffle(NEU)\n",
    "\n",
    "NEG = NEG[:len(NEG)]\n",
    "POS = POS[:len(NEG)]\n",
    "NEU = NEU[:len(NEG)]\n",
    "\n",
    "SUBSET = NEG + POS + NEU\n",
    "SUBSET_PATH = Path('/home/jovyan/work/output/subset')\n",
    "\n",
    "print(len(NEG), len(POS), len(NEU))\n",
    "print(len(SUBSET))\n",
    "\n",
    "\n",
    "for image in tqdm(SUBSET):\n",
    "    #print(image)\n",
    "    res_path = Path('/home/jovyan/work/output/subset') / Path(image).parent.parent.name / Path(image).parent.name\n",
    "    Path(res_path).mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        shutil.copy(str(image), res_path)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "len(list(Path('/home/jovyan/work/output/subset').rglob('*.jpg')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = 'feature-extraction'\n",
    "TRANSFER = 'transfer-learning'\n",
    "FINETUNE = 'fine-tuning'\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data_path, img_size, transforms=None, phase='train'):\n",
    "        self.data_path = Path(data_path) / phase\n",
    "        self.img_size = img_size\n",
    "        self.transform = transforms[phase]\n",
    "        self.phase = phase\n",
    "\n",
    "        self.classes = self._get_classes()\n",
    "        self.image_paths = self._get_image_paths()\n",
    "        self.num_classes = len(self.classes)\n",
    "\n",
    "        self.class_to_int = {class_name: idx for idx, class_name in enumerate(self.classes)}\n",
    "        self.int_to_class = {idx: class_name for class_name, idx in self.class_to_int.items()}\n",
    "\n",
    "    def _get_classes(self):\n",
    "        return [f.name for f in self.data_path.iterdir() if f.is_dir()]\n",
    "\n",
    "    def _get_image_paths(self):\n",
    "        paths = list(self.data_path.rglob('*.jpg'))\n",
    "        random.shuffle(paths)\n",
    "        return paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx])\n",
    "        img_path = self.image_paths[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = Path(img_path).parent.name\n",
    "        label = self.class_to_int[label]  # Convert label to integer\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def show_samples(self):\n",
    "        fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "        for i in range(10):\n",
    "            ax = fig.add_subplot(1, 10, i + 1)\n",
    "            _, label = self.__getitem__(i)\n",
    "            img_cv2 = self.get_cv2_img(i)\n",
    "\n",
    "            ax.imshow(img_cv2, cmap='gray')\n",
    "            ax.set_title(self.int_to_class[label])  # Show class name instead of index\n",
    "            ax.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def show_distribution(self):\n",
    "        labels_count = Counter([self.__getitem__(i)[1] for i in range(len(self.image_paths))])\n",
    "        sorted_counts = sorted(labels_count.items())\n",
    "        labels, counts = zip(*sorted_counts)\n",
    "\n",
    "        plt.figure(figsize=(10, 3))\n",
    "        bars = plt.bar(labels, counts, color='skyblue')\n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Counts per Class')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "        for bar, count in zip(bars, counts):\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5, count,\n",
    "                    ha='center', va='bottom', color='black', fontsize=8)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def get_cv2_img(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        return cv2.imread(str(img_path))\n",
    "\n",
    "    def idx_to_class(self, idx_list):\n",
    "        return [self.int_to_class[idx] for idx in idx_list]\n",
    "\n",
    "    def class_to_idx(self, class_list):\n",
    "        return [self.class_to_int[class_name] for class_name in class_list]\n",
    "\n",
    "    def print_info(self):\n",
    "        print(f\"[INFO] Total number of images: {len(self)}\")\n",
    "        print(\"[INFO] Number of classes:\", self.num_classes)\n",
    "        print(\"[INFO] Classes:\", self.classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    TRAIN: transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    VAL: transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    TEST: transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = { x: Dataset(PATH, img_size=224, transforms=data_transforms, phase=x) for x in [TRAIN, VAL, TEST] }\n",
    "dataloaders = { x: torch.utils.data.DataLoader(datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in [TRAIN, VAL, TEST] }\n",
    "dataset_sizes = { x : len(datasets[x]) for x in [TRAIN, VAL, TEST] }\n",
    "n_classes = datasets[TRAIN].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes[TRAIN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the VGG model\n",
    "vgg16 = models.vgg16(weights='IMAGENET1K_V1')\n",
    "vgg16 = vgg16.to(DEVICE)\n",
    "\n",
    "summary(vgg16, input_size=(3, 224, 224), batch_size=BATCH_SIZE, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# freeze parameters for feature extraction\n",
    "for param in vgg16.features.parameters():\n",
    "    param.require_grad = False\n",
    "\n",
    "vgg16.classifier = torch.nn.Identity()\n",
    "vgg16.classifier = vgg16.classifier.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(loader, conv_base):\n",
    "    conv_base.eval()\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (images, targets) in loader:\n",
    "            # move data to cuda\n",
    "            images = images.to(DEVICE)\n",
    "            targets = torch.as_tensor(targets).to(DEVICE)\n",
    "            \n",
    "            # Extract features using conv_base\n",
    "            features_batch = conv_base(images)\n",
    "            features.append(features_batch.cpu().numpy())  # Convert to numpy array\n",
    "            labels.append(targets.cpu().numpy())\n",
    "\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "\n",
    "train_features, train_labels = extract_features(loader=dataloaders[TRAIN], conv_base=vgg16)\n",
    "test_features, test_labels = extract_features(loader=dataloaders[TEST], conv_base=vgg16)\n",
    "val_features, val_labels = extract_features(loader=dataloaders[VAL], conv_base=vgg16)\n",
    "\n",
    "elapsed_time = time.time() - since\n",
    "print(f\"Feature Extraction completed in {elapsed_time // 60:.0f}m {elapsed_time % 60:.0f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate((train_features, test_features, val_features))\n",
    "labels = np.concatenate((train_labels, test_labels, val_labels))\n",
    "\n",
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(features)\n",
    "red_num = int(num_samples * 0.10)\n",
    "print(red_num)\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "subset_features = rng.choice(features, red_num)\n",
    "subset_labels = rng.choice(labels, red_num)\n",
    "print(subset_features.shape, subset_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values, counts = np.unique(subset_labels, return_counts=True)\n",
    "\n",
    "# Print the results\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"{value} occurs {count} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(subset_features, subset_labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, stratify\u001b[38;5;241m=\u001b[39msubset_labels, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_train\u001b[38;5;241m.\u001b[39mshape, x_test\u001b[38;5;241m.\u001b[39mshape, y_train\u001b[38;5;241m.\u001b[39mshape, y_test\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(subset_features, subset_labels, test_size=0.2, shuffle=True, stratify=subset_labels, random_state=42)\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "\n",
    "classifier = SVC()\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "elapsed_time = time.time() - since\n",
    "print(f\"Training SVM completed in {elapsed_time // 60:.0f}m {elapsed_time % 60:.0f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(clf, x_train, y_train, x_test, y_test, train=True):\n",
    "    if train:\n",
    "        y_prediction = clf.predict(x_train)\n",
    "        clf_report = classification_report(y_train, y_prediction)\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, y_prediction) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, y_prediction)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        y_prediction = clf.predict(x_test)\n",
    "        clf_report = classification_report(y_test, y_prediction)\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, y_prediction) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, y_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(accuracy, precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(classifier, x_train, y_train, x_test, y_test, train=True)\n",
    "print_score(classifier, x_train, y_train, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a OneVsRestClassifier with SVM\n",
    "classifier_ovr = OneVsRestClassifier(SVC(probability=True))\n",
    "classifier_ovr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = classifier_ovr.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_bin = label_binarize(y_test, classes=classifier_ovr.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(classifier_ovr.classes_)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves for each class\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = cycle(['blue', 'red', 'green'])  # Adjust colors as needed\n",
    "for i, color in zip(range(len(classifier_ovr.classes_)), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for SVM (One-vs-Rest)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Train a OneVsRestClassifier with SVM\n",
    "classifier_ovr = OneVsRestClassifier(SVC(probability=True))\n",
    "classifier_ovr.fit(x_train, y_train)\n",
    "\n",
    "# Get predicted probabilities for each class\n",
    "y_score = classifier_ovr.predict_proba(x_test)\n",
    "\n",
    "# Binarize the labels for ROC curve calculation\n",
    "y_test_bin = label_binarize(y_test, classes=classifier_ovr.classes_)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(classifier_ovr.classes_)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves for each class\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = cycle(['blue', 'red', 'green'])  # Adjust colors as needed\n",
    "for i, color in zip(range(len(classifier_ovr.classes_)), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for SVM (One-vs-Rest)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "pickle.dump(best_estimator, open('/home/jovyan/work/model.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits_values = [3, 5, 10]\n",
    "\n",
    "for n_splits in n_splits_values:\n",
    "    cv = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "    scores = cross_val_score(best_estimator, features, labels, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    print(f\"{n_splits}-Fold CV: {scores.mean():.2f} accuracy with a standard deviation of {scores.std():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
