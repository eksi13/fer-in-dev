{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import successful\n",
      "gpu accessible\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try: \n",
    "    import cv2\n",
    "    import torch\n",
    "    import torchvision\n",
    "    import sklearn.svm\n",
    "except:\n",
    "    %pip install opencv-python-headless==4.9.0.80\n",
    "    %pip install torch\n",
    "    %pip install torchvision\n",
    "    %pip install torchsummary \n",
    "    %pip install sklearn\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import cuda\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "from PIL import Image\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "print('import successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Train on gpu ...True\n",
      "[INFO] 2 gpus detected.\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Data paths\n",
    "EMOREACT = Path('EmoReact')\n",
    "FER = Path('FER-2013')\n",
    "KDEF = Path('KDEF-AKDEF')\n",
    "NIMH = Path('NIMH-CHEFS')\n",
    "\n",
    "# General paths\n",
    "BASE_PATH = Path('/home/jovyan/work/data/out')\n",
    "MODEL_PATH = Path('/home/jovyan/work/models')\n",
    "\n",
    "# Set dataset here\n",
    "DATA = EMOREACT\n",
    "\n",
    "# Dataset-specific paths\n",
    "CURRENT_PATH = BASE_PATH / DATA\n",
    "LABELS = [f.name for f in CURRENT_PATH.iterdir() if f.is_dir()]\n",
    "IMAGE_PATHS = list(CURRENT_PATH.rglob('*.jpg'))\n",
    "\n",
    "# Constants for splitting dataset\n",
    "TRAIN = 'train'\n",
    "TEST = 'test'\n",
    "VAL = 'val'\n",
    "\n",
    "FEATURES = 'feature-extraction'\n",
    "TRANSFER = 'transfer-learning'\n",
    "FINETUNE = 'fine-tuning'\n",
    "\n",
    "# batch size\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# CUDA\n",
    "train_on_gpu = cuda.is_available()\n",
    "print(f'[INFO] Train on gpu ...{train_on_gpu}')\n",
    "if train_on_gpu:\n",
    "    gpu_count = cuda.device_count()\n",
    "    print(f'[INFO] {gpu_count} gpus detected.')\n",
    "    if gpu_count > 1:\n",
    "        multi_gpu = True\n",
    "    else:\n",
    "        multi_gpu = False\n",
    "        \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data_path, img_size, transforms=None, phase='train'):\n",
    "        self.data_path = Path(data_path) / phase\n",
    "        self.img_size = img_size\n",
    "        self.transform = transforms[phase]\n",
    "        self.phase = phase\n",
    "\n",
    "        self.classes = self._get_classes()\n",
    "        self.image_paths = self._get_image_paths()\n",
    "        self.num_classes = len(self.classes)\n",
    "\n",
    "        self.class_to_int = {class_name: idx for idx, class_name in enumerate(self.classes)}\n",
    "        self.int_to_class = {idx: class_name for class_name, idx in self.class_to_int.items()}\n",
    "\n",
    "    def _get_classes(self):\n",
    "        return [f.name for f in self.data_path.iterdir() if f.is_dir()]\n",
    "\n",
    "    def _get_image_paths(self):\n",
    "        paths = list(self.data_path.rglob('*.jpg'))\n",
    "        random.shuffle(paths)\n",
    "        return paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx])\n",
    "        img_path = self.image_paths[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = Path(img_path).parent.name\n",
    "        label = self.class_to_int[label]  # Convert label to integer\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def show_samples(self):\n",
    "        fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "        for i in range(10):\n",
    "            ax = fig.add_subplot(1, 10, i + 1)\n",
    "            _, label = self.__getitem__(i)\n",
    "            img_cv2 = self.get_cv2_img(i)\n",
    "\n",
    "            ax.imshow(img_cv2, cmap='gray')\n",
    "            ax.set_title(self.int_to_class[label])  # Show class name instead of index\n",
    "            ax.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def show_distribution(self):\n",
    "        labels_count = Counter([self.__getitem__(i)[1] for i in range(len(self.image_paths))])\n",
    "        sorted_counts = sorted(labels_count.items())\n",
    "        labels, counts = zip(*sorted_counts)\n",
    "\n",
    "        plt.figure(figsize=(10, 3))\n",
    "        bars = plt.bar(labels, counts, color='skyblue')\n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Counts per Class')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "        for bar, count in zip(bars, counts):\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5, count,\n",
    "                    ha='center', va='bottom', color='black', fontsize=8)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def get_cv2_img(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        return cv2.imread(str(img_path))\n",
    "\n",
    "    def idx_to_class(self, idx_list):\n",
    "        return [self.int_to_class[idx] for idx in idx_list]\n",
    "\n",
    "    def class_to_idx(self, class_list):\n",
    "        return [self.class_to_int[class_name] for class_name in class_list]\n",
    "\n",
    "    def print_info(self):\n",
    "        print(f\"[INFO] Total number of images: {len(self)}\")\n",
    "        print(\"[INFO] Number of classes:\", self.num_classes)\n",
    "        print(\"[INFO] Classes:\", self.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    TRAIN: transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    VAL: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    TEST: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "datasets = { x: Dataset(CURRENT_PATH, img_size=224, transforms=data_transforms, phase=x) for x in [TRAIN, VAL, TEST] }\n",
    "dataloaders = { x: torch.utils.data.DataLoader(datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4) for x in [TRAIN, VAL, TEST] }\n",
    "dataset_sizes = { x : len(datasets[x]) for x in [TRAIN, VAL, TEST] }\n",
    "\n",
    "N_CLASSES = datasets[TRAIN].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the VGG model\n",
    "vgg16 = models.vgg16(weights='IMAGENET1K_V1')\n",
    "vgg16 = vgg16.to(DEVICE)\n",
    "\n",
    "# freeze parameters for feature extraction\n",
    "for param in vgg16.features.parameters():\n",
    "    param.require_grad = False\n",
    "\n",
    "# number of input features for last layer\n",
    "num_features = vgg16.classifier[6].in_features\n",
    "\n",
    "vgg16.classifier = torch.nn.Identity()\n",
    "vgg16.classifier = vgg16.classifier.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(loader, conv_base):\n",
    "    conv_base.eval()\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in loader:\n",
    "            # move data to cuda\n",
    "            images = images.to(device)\n",
    "            targets = torch.as_tensor(targets).to(device)\n",
    "            \n",
    "            # Extract features using conv_base\n",
    "            features_batch = conv_base(images)\n",
    "            features.append(features_batch.cpu().numpy())  # Convert to numpy array\n",
    "            labels.append(targets.cpu().numpy())\n",
    "\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = extract_features(loader=dataloaders[TRAIN], conv_base=vgg16)\n",
    "val_features, val_labels = extract_features(loader=dataloaders[VAL], conv_base=vgg16)\n",
    "test_features, test_labels = extract_features(loader=dataloaders[TEST], conv_base=vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 25088)\n"
     ]
    }
   ],
   "source": [
    "print((train_features).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19407894736842105\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = SVC()\n",
    "clf.fit(train_features, train_labels)\n",
    "predicted = clf.predict(test_features)\n",
    "# get the accuracy\n",
    "print(accuracy_score(test_labels, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(vgg, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    since = time.time()\n",
    "    \n",
    "    # freeze feature layers\n",
    "    for param in vgg.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # make classifier trainable\n",
    "    for param in vgg.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    \"\"\"\n",
    "    for param in vgg.features.parameters():\n",
    "        param.requires_grad = True\n",
    "    \"\"\"\n",
    "    vgg.classifier[-1] = torch.nn.Linear(in_features=vgg.classifier[-1].in_features, out_features=N_CLASSES)\n",
    "    vgg = vgg.to(DEVICE)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    avg_loss_val = 0\n",
    "    avg_acc_val = 0\n",
    "\n",
    "    train_batches = len(dataloaders[TRAIN])\n",
    "    val_batches = len(dataloaders[VAL])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "        print('-' * 10)\n",
    "\n",
    "        loss_train = 0\n",
    "        loss_val = 0\n",
    "        acc_train = 0\n",
    "        acc_val = 0\n",
    "        \n",
    "        vgg.train(True)\n",
    "\n",
    "        # iterate through batches of training set\n",
    "        for i, data in enumerate(dataloaders[TRAIN]):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"\\rTraining batch {i}/{train_batches}\", flush=True)\n",
    "            \n",
    "            # set input and labels to the batch features and labels\n",
    "            inputs = data[0]\n",
    "            labels = data[1]\n",
    "\n",
    "            # move to cuda if possible\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            # do the learning stuff & update loss etc.\n",
    "            optimizer_ft.zero_grad()\n",
    "            outputs = vgg(inputs)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            # backward & optimize\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer_ft.step()                \n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            acc_train += torch.sum(preds == labels.data)\n",
    "            \n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        print()\n",
    "        avg_loss = loss_train / dataset_sizes[TRAIN]\n",
    "        avg_acc = acc_train / dataset_sizes[TRAIN]\n",
    "\n",
    "        # set to evaluation mode\n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "\n",
    "        # iterate through batches of validation set\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(dataloaders[VAL]):\n",
    "                if i % 100 == 0:\n",
    "                    print(f\"\\rValidation batch {i}/{val_batches}\", flush=True)\n",
    "                \n",
    "                # set input and labels to the batch features and labels\n",
    "                inputs = data[0]\n",
    "                labels = data[1]\n",
    "    \n",
    "                # move to cuda if possible\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "    \n",
    "                # do the learning stuff & update loss etc.\n",
    "                # zero the gradients\n",
    "                optimizer_ft.zero_grad()\n",
    "                outputs = vgg(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss_val += loss.item()\n",
    "                acc_val += torch.sum(preds == labels.data)\n",
    "                \n",
    "            # delete batch from cuda \n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_loss_val = loss_val / dataset_sizes[VAL]\n",
    "        avg_acc_val = acc_val / dataset_sizes[VAL]\n",
    "\n",
    "        # print results\n",
    "        print()\n",
    "        print(f\"Epoch {epoch} result: \".format(epoch))\n",
    "        print(f\"Avg loss (train): {avg_loss:.4f}\")\n",
    "        print(f\"Avg acc (train): {avg_acc:.4f}\")\n",
    "        print(f\"Avg loss (val): {avg_loss_val:.4f}\")\n",
    "        print(f\"Avg acc (val): {avg_acc_val:.4f}\")\n",
    "        print('-' * 10)\n",
    "        print()\n",
    "\n",
    "        # update best acc save best model weights\n",
    "        if avg_acc_val > best_acc:\n",
    "            best_acc = avg_acc_val\n",
    "            best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "\n",
    "    # compute training time\n",
    "    elapsed_time = time.time() - since\n",
    "\n",
    "    # print all the results\n",
    "    print()\n",
    "    print(f\"Training completed in {elapsed_time // 60:.0f}m {elapsed_time % 60:.0f}s\")\n",
    "    print(f\"Best acc: {best_acc:.4f}\")\n",
    "\n",
    "    return vgg.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the VGG model\n",
    "vgg16 = models.vgg16(weights='IMAGENET1K_V1')\n",
    "vgg16 = vgg16.to(DEVICE)\n",
    "\n",
    "#summary(vgg16, input_size=(3, 224, 224), batch_size=BATCH_SIZE, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = train_model(vgg16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vgg16.state_dict(), 'VGG16_NIMH-CHEFS.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(vgg, criterion):\n",
    "    since = time.time()\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    loss_test = 0\n",
    "    acc_test = 0\n",
    "    \n",
    "    test_batches = len(dataloaders[TEST])\n",
    "    print(\"Evaluating model\")\n",
    "    print('-' * 10)\n",
    "    \n",
    "    for i, data in enumerate(dataloaders[TEST]):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"\\rTest batch {i}/{test_batches}\", flush=True)\n",
    "\n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "        inputs = data[0]\n",
    "        labels = data[1]\n",
    "\n",
    "        # move to cuda if possible\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        # Ddsable gradient calculation for evaluation\n",
    "        with torch.no_grad():  \n",
    "            outputs = vgg(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        loss_test += loss.item()\n",
    "        acc_test += torch.sum(preds == labels.data)\n",
    "\n",
    "        del inputs, labels, outputs, preds\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "    avg_loss = loss_test / dataset_sizes[TEST]\n",
    "    avg_acc = acc_test / dataset_sizes[TEST]\n",
    "    \n",
    "    elapsed_time = time.time() - since\n",
    "    print()\n",
    "    print(f\"Evaluation completed in {elapsed_time // 60:.0f}m {elapsed_time % 60:.0f}s\")\n",
    "    print(f\"Avg loss (test): {avg_loss:.4f}\")\n",
    "    print(f\"Avg acc (test): {avg_acc:.4f}\")\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(vgg16, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
