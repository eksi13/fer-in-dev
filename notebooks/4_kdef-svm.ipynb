{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import pickle, shutil, random\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IN_PATH = Path('/project/volume/data/out/KDEF-AKDEF/KDEF_and_AKDEF/KDEF')\n",
    "LABELS = ['Afraid', 'Angry', 'Disgust', 'Happy', 'Neutral', 'Sad', 'Surprised']\n",
    "\n",
    "BASE_PATH = Path('/project/volume/data/out/KDEF-AKDEF/')\n",
    "\n",
    "PROJ_PATH = Path('/project')\n",
    "\n",
    "JPGS = list(BASE_PATH.rglob('*.JPG'))\n",
    "\n",
    "print(len(JPGS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ipynb_checkpoints(path):\n",
    "    for checkpoint_dir in Path(path).rglob('.ipynb_checkpoints'):\n",
    "        print(\"Removing directory:\", checkpoint_dir)\n",
    "        for file in os.listdir(checkpoint_dir):\n",
    "            file_path = os.path.join(checkpoint_dir, file)\n",
    "            os.unlink(file_path)\n",
    "        os.rmdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workaround: move files to container, rename, move back :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files(file_list, destination):\n",
    "    for file in tqdm(file_list):\n",
    "        dest_path = destination / 'KDEF' / file.parent.name\n",
    "        dest_file = destination / 'KDEF' / file.parent.name / file.name\n",
    "        dest_path.mkdir(parents=True, exist_ok=True)\n",
    "        if file.exists() and not dest_file.exists():\n",
    "            shutil.move(str(file), dest_path)\n",
    "\n",
    "def rename_jpg_files(file_list):\n",
    "    for file in tqdm(file_list):\n",
    "        image_path = Path(file)\n",
    "        new_path = image_path.with_suffix('.jpg')\n",
    "        image_path.rename(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_files(JPGS, PROJ_PATH)\n",
    "\n",
    "proj_jpgs = list((PROJ_PATH / 'KDEF').rglob('*.JPG'))\n",
    "rename_jpg_files(proj_jpgs)\n",
    "new_jpgs = list((PROJ_PATH / 'KDEF').rglob('*.jpg'))\n",
    "\n",
    "move_files(new_jpgs, BASE_PATH)\n",
    "\n",
    "if Path(PROJ_PATH / 'KDEF').exists():\n",
    "    shutil.rmtree(str(PROJ_PATH / 'KDEF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATHS = list(BASE_PATH.rglob('*.jpg'))\n",
    "IMAGE_PATHS_STR = [str(path) for path in IMAGE_PATHS]\n",
    "\n",
    "EMOTION_FOLDERS = {\n",
    "        'AF': 'Afraid',\n",
    "        'AN': 'Angry',\n",
    "        'DI': 'Disgusted',\n",
    "        'HA': 'Happy',\n",
    "        'NE': 'Neutral',\n",
    "        'SA': 'Sad',\n",
    "        'SU': 'Surprised'\n",
    "        }\n",
    "\n",
    "print(len(IMAGE_PATHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_folders():\n",
    "    for label in tqdm(LABELS):\n",
    "        dest_path = BASE_PATH / label\n",
    "        dest_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def move_to_folder():\n",
    "    for file in tqdm(IMAGE_PATHS):\n",
    "        name = file.stem\n",
    "        emotion = name[4:6]\n",
    "        folder_name = EMOTION_FOLDERS.get(emotion)\n",
    "        if folder_name:\n",
    "            dest_path = BASE_PATH / folder_name / file.name\n",
    "            if not dest_path.exists():\n",
    "                dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.move(str(file), str(dest_path))\n",
    "    if Path(BASE_PATH / 'KDEF').exists():\n",
    "        shutil.rmtree(str(BASE_PATH / 'KDEF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_label_folders()\n",
    "move_to_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_ipynb_checkpoints(Path('/project/volume/data/out'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATHS = list(BASE_PATH.rglob('*.jpg'))\n",
    "IMAGE_PATHS_STR = [str(path) for path in IMAGE_PATHS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    fig.add_subplot(1, 10, i + 1)\n",
    "    plt.imshow(np.array(cv2.imread(str(IMAGE_PATHS[i]))), cmap='gray')\n",
    "    label = Path(IMAGE_PATHS[i]).parent.name\n",
    "    plt.title(label)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution():\n",
    "    nbr_per_cat = Counter(Path(file).parent.name for file in IMAGE_PATHS)\n",
    "    print(dict(nbr_per_cat))\n",
    "\n",
    "    categories = list(nbr_per_cat.keys())\n",
    "    counts = list(nbr_per_cat.values())\n",
    "\n",
    "    plt.figure(figsize=(9, 3))\n",
    "    bars = plt.bar(categories, counts, width=0.5)\n",
    "\n",
    "    plt.xlabel('Categories')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.title('Number of Files per Category')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    for bar, count in zip(bars, counts):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(count), \n",
    "                ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "get_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prop = 0.6\n",
    "test_prop = 0.2\n",
    "valid_prop = 0.2\n",
    "\n",
    "number_of_images = len(list(BASE_PATH.rglob('*.jpg')))\n",
    "\n",
    "n_train = int((number_of_images * train_prop) + 0.5)\n",
    "n_valid = int((number_of_images * valid_prop) + 0.5)\n",
    "n_test = number_of_images - n_train - n_valid\n",
    "\n",
    "print(f\"[INFO] Number of images used in training ... {str(n_train)} ({str(train_prop * 100)}%)\")\n",
    "print(f\"[INFO] Number of images used in validation ...{str(n_valid)} ({str(valid_prop * 100)}%)\")\n",
    "print(f\"[INFO] Number of images used in testing ... {str(n_test)} ({str(test_prop * 100)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_move():\n",
    "    for label in tqdm(LABELS):\n",
    "        train_destination = BASE_PATH / \"train\" / label\n",
    "        val_destination = BASE_PATH / \"val\" / label\n",
    "        test_destination = BASE_PATH / \"test\" / label\n",
    "\n",
    "        train_destination.mkdir(parents=True, exist_ok=True)\n",
    "        val_destination.mkdir(parents=True, exist_ok=True)\n",
    "        test_destination.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        files = list((BASE_PATH / \"train\").rglob('*.jpg'))\n",
    "        random.shuffle(files)\n",
    "\n",
    "        train_n = (int((len(files) * train_prop) + 0.5))\n",
    "        val_n = (int((len(files) * valid_prop) + 0.2))\n",
    "        \n",
    "        for file_idx, file in enumerate(files):\n",
    "            if file_idx < train_n:\n",
    "                shutil.move(str(file), train_destination)\n",
    "            elif file_idx < train_n + val_n:\n",
    "                shutil.move(str(file), val_destination)\n",
    "            else:\n",
    "                shutil.move(str(file), test_destination)\n",
    "\n",
    "        if BASE_PATH.exists() and BASE_PATH.is_dir():\n",
    "            shutil.rmtree(BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_and_move()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(clf, x_train, y_train, x_test, y_test, train=True):\n",
    "    if train:\n",
    "        y_prediction = clf.predict(x_train)\n",
    "        clf_report = classification_report(y_train, y_prediction)\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, y_prediction) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, y_prediction)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        y_prediction = clf.predict(x_test)\n",
    "        clf_report = classification_report(y_test, y_prediction)\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, y_prediction) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, y_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_grayscale(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "\n",
    "def resize_image(img, size):\n",
    "    return cv2.resize(img, (size,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(image_shape, orientations, pixels_per_cell, cells_per_block):\n",
    "    compute_hog_feature_size(image_shape, orientations, pixels_per_cell, cells_per_block)\n",
    "    hog_data = []\n",
    "    hog_labels = []\n",
    "\n",
    "    for p in tqdm(IMAGE_PATHS):\n",
    "        im = to_grayscale(str(p))\n",
    "        im = resize_image(im, image_shape)\n",
    "        \n",
    "        # extract hog feature descriptor\n",
    "        fd1 = hog(im, orientations=orientations, pixels_per_cell=(pixels_per_cell, pixels_per_cell),\n",
    "                  cells_per_block=(cells_per_block, cells_per_block), \n",
    "                  block_norm='L2-Hys',\n",
    "                  transform_sqrt=False,\n",
    "                  feature_vector=True)\n",
    "\n",
    "        label = Path(p).parent.name\n",
    "        hog_labels.append(label)\n",
    "        hog_data.append(fd1)\n",
    "\n",
    "    hog_data = np.array(hog_data)\n",
    "    hog_labels = np.array(hog_labels)\n",
    "    print(\"[INFO] Number of features ...\", str(hog_data.shape[1]))\n",
    "    print(\"[INFO] Number of labels ...\", str(hog_labels.shape[0]))\n",
    "    return hog_data, hog_labels\n",
    "\n",
    "def compute_hog_feature_size(image_shape, orientations, pixels_per_cell, cells_per_block):\n",
    "    height, width = image_shape, image_shape\n",
    "    num_cells_x = width // pixels_per_cell\n",
    "    num_cells_y = height // pixels_per_cell\n",
    "    num_blocks_x = num_cells_x - cells_per_block + 1\n",
    "    num_blocks_y = num_cells_y - cells_per_block + 1\n",
    "    features_per_block = cells_per_block * cells_per_block * orientations\n",
    "    total_features = num_blocks_x * num_blocks_y * features_per_block\n",
    "    print(\"[INFO] Size of HOG feature vector ...\", total_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_data, hog_labels = extract_hog_features(64, 7, 8, 4)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(hog_data, hog_labels, test_size=0.2, shuffle=True, stratify=hog_labels, random_state=42)\n",
    "print(\"[INFO] Number of images used in training ...\", x_train.shape[0])\n",
    "print(\"[INFO] Number of images used in testing ...\", x_test.shape[0])\n",
    "\n",
    "classifier = SVC()\n",
    "parameters = {'gamma': [0.1], 'C': [1]}\n",
    "\n",
    "grid_search = GridSearchCV(classifier, parameters, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "best_estimator_hog = grid_search.best_estimator_\n",
    "print(\"[INFO] Best params ...\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path('/project/volume/models/kdef/hog_model.p')\n",
    "model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pickle.dump(best_estimator_hog, open(model_path, 'wb'))\n",
    "\n",
    "print_score(best_estimator_hog, x_train, y_train, x_test, y_test, train=True)\n",
    "print_score(best_estimator_hog, x_train, y_train, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe import Image\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_mesh = '/project/volume/models/face_landmarker.task'\n",
    "\n",
    "base_options_mesh = python.BaseOptions(model_asset_path=model_path_mesh)\n",
    "options_mesh = vision.FaceLandmarkerOptions(base_options=base_options_mesh,\n",
    "                                       output_face_blendshapes=True,\n",
    "                                       output_facial_transformation_matrixes=True,\n",
    "                                       num_faces=1)\n",
    "detector_mesh = vision.FaceLandmarker.create_from_options(options_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mp_cv2_image(image_path):\n",
    "    return Image.create_from_file(str(image_path)), cv2.imread(str(image_path))\n",
    "\n",
    "def colortogray(img):\n",
    "    imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return imgray\n",
    "\n",
    "def resizeImage(image, size):\n",
    "    return cv2.resize(image, (size,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_landmarks():\n",
    "    lm_labels = []\n",
    "    lm_data = []\n",
    "\n",
    "    for file in tqdm(IMAGE_PATHS):\n",
    "        img_cv2 = to_grayscale(str(file))\n",
    "        img_cv2 = resize_image(img_cv2, 128)\n",
    "        rgb_frame = mp.Image(image_format=mp.ImageFormat.SRGB, data=img_cv2)\n",
    "        detection_result = detector_mesh.detect(rgb_frame)\n",
    "\n",
    "        if detection_result.face_landmarks:\n",
    "            lm_array = np.array([[lm.x, lm.y, lm.z] for lm in detection_result.face_landmarks[0]]).flatten()\n",
    "            lm_labels.append(file.parent.name)\n",
    "            lm_data.append(lm_array)\n",
    "\n",
    "    lm_labels = np.array(lm_labels)\n",
    "    lm_data = np.array(lm_data)\n",
    "\n",
    "    return lm_data, lm_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_data, lm_labels = extract_landmarks()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(lm_data, lm_labels, test_size=0.2, shuffle=True, stratify=hog_labels, random_state=42)\n",
    "print(\"[INFO] Number of images used in training ...\", x_train.shape[0])\n",
    "print(\"[INFO] Number of images used in testing ...\", x_test.shape[0])\n",
    "\n",
    "classifier = SVC()\n",
    "parameters = {'gamma': [0.1, 0.01, 0.001], 'C': [1, 10, 100, 1000]}\n",
    "\n",
    "grid_search = GridSearchCV(classifier, parameters, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "best_estimator_landmark = grid_search.best_estimator_\n",
    "print(\"[INFO] Best params ...\", grid_search.best_params_)\n",
    "pickle.dump(best_estimator_landmark, open('/project/volume/models/lm_model.p', 'wb'))\n",
    "\n",
    "print_score(best_estimator_landmark, x_train, y_train, x_test, y_test, train=True)\n",
    "print_score(best_estimator_landmark, x_train, y_train, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_pixels():\n",
    "    pixel_labels = []\n",
    "    pixel_data = []\n",
    "\n",
    "    for file in tqdm(IMAGE_PATHS):     \n",
    "        img_cv2 = to_grayscale(str(file))\n",
    "        img_cv2 = resize_image(img_cv2, 128)\n",
    "        \n",
    "        pixel_labels.append(file.parent.name)\n",
    "        pixel_data.append(np.array(img_cv2).flatten())\n",
    "\n",
    "    pixel_labels = np.array(pixel_labels)\n",
    "    pixel_data = np.array(pixel_data)\n",
    "\n",
    "    return pixel_data, pixel_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_data, pixel_labels = pure_pixels()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(pixel_data, pixel_labels, test_size=0.2, shuffle=True, stratify=hog_labels, random_state=42)\n",
    "print(\"[INFO] Number of images used in training ...\", x_train.shape[0])\n",
    "print(\"[INFO] Number of images used in testing ...\", x_test.shape[0])\n",
    "\n",
    "classifier = SVC()\n",
    "parameters = {'gamma': [0.1, 0.01, 0.001], 'C': [1, 10, 100, 1000]}\n",
    "\n",
    "grid_search = GridSearchCV(classifier, parameters, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "best_estimator_pixel = grid_search.best_estimator_\n",
    "print(\"[INFO] Best params ...\", grid_search.best_params_)\n",
    "pickle.dump(best_estimator_pixel, open('/project/volume/models/pixel_model.p', 'wb'))\n",
    "\n",
    "print_score(best_estimator_pixel, x_train, y_train, x_test, y_test, train=True)\n",
    "print_score(best_estimator_pixel, x_train, y_train, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blendshapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_blendshapes():\n",
    "    bs_labels = []\n",
    "    bs_data = []\n",
    "\n",
    "    for file in tqdm(IMAGE_PATHS):\n",
    "        img_cv2 = to_grayscale(str(file))\n",
    "        img_cv2 = resize_image(img_cv2, 64)\n",
    "        \n",
    "        rgb_frame = mp.Image(image_format=mp.ImageFormat.SRGB, data=img_cv2)\n",
    "        detection_result = detector_mesh.detect(rgb_frame)\n",
    "\n",
    "        if detection_result.face_blendshapes:\n",
    "            bs_array = np.array([[bs.index, bs.score] for bs in detection_result.face_blendshapes[0]]).flatten()\n",
    "            bs_labels.append(file.parent.name)\n",
    "            bs_data.append(bs_array)\n",
    "\n",
    "    bs_labels = np.array(bs_labels)\n",
    "    bs_data = np.array(bs_data)\n",
    "\n",
    "    return bs_data, bs_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_data, bs_labels = extract_blendshapes()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(bs_data, bs_labels, test_size=0.2, shuffle=True, stratify=bs_labels, random_state=42)\n",
    "print(\"[INFO] Number of images used in training ...\", x_train.shape[0])\n",
    "print(\"[INFO] Number of images used in testing ...\", x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC()\n",
    "parameters = {'gamma': [0.1, 0.01, 0.001], 'C': [1, 10, 100, 1000]}\n",
    "\n",
    "grid_search = GridSearchCV(classifier, parameters, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "best_estimator_blendshapes = grid_search.best_estimator_\n",
    "print(\"[INFO] Best params ...\", grid_search.best_params_)\n",
    "pickle.dump(best_estimator_blendshapes, open('/project/volume/models/blenshape_model.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(best_estimator_pixel, x_train, y_train, x_test, y_test, train=True)\n",
    "print_score(best_estimator_pixel, x_train, y_train, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold Cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits_values = [3, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC()\n",
    "parameters = {'gamma': [0.1, 0.01, 0.001], 'C': [1, 10, 100, 1000]}\n",
    "\"\"\"\n",
    "modes = {'hog': best_estimator_hog, \n",
    "         'pixel': best_estimator_pixel,\n",
    "         'landmark': best_estimator_landmark, \n",
    "         'blendshapes': best_estimator_blendshapes\n",
    "         }\n",
    "\"\"\"\n",
    "modes = {\n",
    "         'blendshapes': best_estimator_blendshapes\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode, model in modes.items():\n",
    "    print(mode)\n",
    "    for n_splits in n_splits_values:\n",
    "        cv = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "        scores = cross_val_score(model, bs_data, bs_labels, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "        print(f\"{n_splits}-Fold CV: {scores.mean():.2f} accuracy with a standard deviation of {scores.std():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
