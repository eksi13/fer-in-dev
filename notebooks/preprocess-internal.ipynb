{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a66307-da72-4033-9d3c-36cc8cc72909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import successful\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    import cv2\n",
    "    import torch\n",
    "    import torchvision\n",
    "    import sklearn.svm\n",
    "    import mediapipe as mp\n",
    "except:\n",
    "    %pip install opencv-python-headless==4.9.0.80\n",
    "    %pip install torch\n",
    "    %pip install torchvision\n",
    "    %pip install torchsummary \n",
    "    %pip install sklearn\n",
    "    %pip install mediapipe\n",
    "\n",
    "\n",
    "import cv2\n",
    "import pickle\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "print('import successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d6a5413-37fe-4fee-9ad3-097424663f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4727\n"
     ]
    }
   ],
   "source": [
    "# General paths\n",
    "CURRENT_PATH = Path('/home/jovyan/work/videos/output/frames')\n",
    "\n",
    "\n",
    "LABELS = ['neutral', 'negative', 'positive']\n",
    "IMAGE_PATHS = list(CURRENT_PATH.rglob('*.jpg'))\n",
    "\n",
    "print(len(IMAGE_PATHS))\n",
    "\n",
    "# Constants for splitting dataset\n",
    "TRAIN = 'train'\n",
    "TEST = 'test'\n",
    "VAL = 'val'\n",
    "\n",
    "# Feature extraction method\n",
    "FEATURE = 'pixel'\n",
    "\n",
    "# Parameters for Histogram of Oriented Gradients (HOG) feature extraction\n",
    "orientations = 7\n",
    "pixels_per_cell = 8\n",
    "cells_per_block = 4\n",
    "\n",
    "hog_params = { \n",
    "    'orientations': orientations,\n",
    "    'pixels_per_cell': pixels_per_cell,\n",
    "    'cells_per_block': cells_per_block\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a188f991-9707-4c60-9756-7b1ce6c2990d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
